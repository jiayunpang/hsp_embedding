{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0df1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c986d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c8b2b21fcaf52a91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/pj11/.cache/huggingface/datasets/csv/default-c8b2b21fcaf52a91/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6a5d1f7df849a88ce037f681aaf64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638a5724eb3b4007a355cdad97514b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/pj11/.cache/huggingface/datasets/csv/default-c8b2b21fcaf52a91/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1113ff78f394a4bba7a7851c1790c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the code is adapted from the \"fine-tuning a pretrained model\" and\n",
    "# \"fine-tuning a model with the trainer API\" course and examples on hugging face\n",
    "# check huggingface for further explanations\n",
    "\n",
    "# load data into training, valdidation and test\n",
    "dataset = load_dataset('csv', data_files={'train':['hansen_p_bert_ds1.csv', 'hansen_p_bert_ds2.csv',\n",
    "                                                   'hansen_p_bert_ds3.csv', 'hansen_p_bert_ds4.csv'],\n",
    "                                          'validation':'hansen_p_bert_ds5.csv',\n",
    "                                          'test': 'hansen_p_bert_ds6.csv'}, delimiter=',', column_names =['smiles', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9874b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': 'CC\\\\C(C)=N\\\\O', 'label': 4.9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data format\n",
    "dataset['validation'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9894c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# specify model from hugging face\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepchem/ChemBERTa-77M-MTR\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b48772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9fa5bcc0774f6d83c26227719fc67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66b31738e9e4ae68f50adfcf398d773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b49987848ce4b9cb7e2a2dd202e7fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009f538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 789\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f040040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=random_state).select(range(1000))\n",
    "#small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=random_state).select(range(1000))\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]\n",
    "small_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b5f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepchem/ChemBERTa-77M-MTR were not used when initializing RobertaForSequenceClassification: ['regression.out_proj.bias', 'norm_mean', 'regression.dense.weight', 'regression.out_proj.weight', 'norm_std', 'regression.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at deepchem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# for regression, num_labels=1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"deepchem/ChemBERTa-77M-MTR\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663b29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90cab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metric\n",
    "mae_metric = evaluate.load(\"mae\")\n",
    "mse_metric = evaluate.load(\"mse\")\n",
    "pearsonr_metric = evaluate.load(\"pearsonr\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update({'mae': mae_metric.compute(predictions=predictions, references=labels)})\n",
    "    metrics.update({'rmse': mse_metric.compute(predictions=predictions, references=labels, squared=False)})\n",
    "    metrics.update({'pearsonr': pearsonr_metric.compute(predictions=predictions, references=labels)})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574f2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the finetuned model\n",
    "para_output_dir = 'C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/'\n",
    "model_output_path = f'{para_output_dir}/model'\n",
    "\n",
    "# specify trainining arguments \n",
    "training_args = TrainingArguments(output_dir=para_output_dir, \n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size = 4,\n",
    "                                  per_device_eval_batch_size = 4,\n",
    "                                  num_train_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794a8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 789\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 3427825\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 09:27, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Pearsonr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>32.999813</td>\n",
       "      <td>{'mae': 4.3853575911770015}</td>\n",
       "      <td>{'mse': 5.760618738828536}</td>\n",
       "      <td>{'pearsonr': 0.1432079271172701}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.771713</td>\n",
       "      <td>{'mae': 3.1292016028147662}</td>\n",
       "      <td>{'mse': 4.115499259915974}</td>\n",
       "      <td>{'pearsonr': 0.13694972432990407}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>15.200443</td>\n",
       "      <td>{'mae': 2.9508277680063006}</td>\n",
       "      <td>{'mse': 3.9190619062333707}</td>\n",
       "      <td>{'pearsonr': 0.3498915673311254}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.657250</td>\n",
       "      <td>{'mae': 2.8312507141665155}</td>\n",
       "      <td>{'mse': 3.7160847692847656}</td>\n",
       "      <td>{'pearsonr': 0.4506257399402354}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.304548</td>\n",
       "      <td>{'mae': 2.804424956365285}</td>\n",
       "      <td>{'mse': 3.666908555979194}</td>\n",
       "      <td>{'pearsonr': 0.4957232410087511}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.555748</td>\n",
       "      <td>{'mae': 2.7788217200845633}</td>\n",
       "      <td>{'mse': 3.5627072981410435}</td>\n",
       "      <td>{'pearsonr': 0.5153311041063423}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.098452</td>\n",
       "      <td>{'mae': 2.711085844766065}</td>\n",
       "      <td>{'mse': 3.4961353100647568}</td>\n",
       "      <td>{'pearsonr': 0.5571548359727206}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.049445</td>\n",
       "      <td>{'mae': 2.6310947013990527}</td>\n",
       "      <td>{'mse': 3.3423437555186846}</td>\n",
       "      <td>{'pearsonr': 0.5902452468381787}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>10.809216</td>\n",
       "      <td>{'mae': 2.580661134671439}</td>\n",
       "      <td>{'mse': 3.304431414538389}</td>\n",
       "      <td>{'pearsonr': 0.6148517953146416}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>10.579213</td>\n",
       "      <td>{'mae': 2.6097256045051034}</td>\n",
       "      <td>{'mse': 3.267475578774824}</td>\n",
       "      <td>{'pearsonr': 0.6165920289982403}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>10.106093</td>\n",
       "      <td>{'mae': 2.5454901567078787}</td>\n",
       "      <td>{'mse': 3.1934798211054787}</td>\n",
       "      <td>{'pearsonr': 0.6373811374854202}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>10.293324</td>\n",
       "      <td>{'mae': 2.498110902037112}</td>\n",
       "      <td>{'mse': 3.2215179500707958}</td>\n",
       "      <td>{'pearsonr': 0.6558586629629499}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.310060</td>\n",
       "      <td>{'mae': 2.336488193893796}</td>\n",
       "      <td>{'mse': 3.0645255201816135}</td>\n",
       "      <td>{'pearsonr': 0.6846951406103133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.433782</td>\n",
       "      <td>{'mae': 2.404265609035637}</td>\n",
       "      <td>{'mse': 3.0840358608475364}</td>\n",
       "      <td>{'pearsonr': 0.6719146632329329}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.190206</td>\n",
       "      <td>{'mae': 2.3369746258869992}</td>\n",
       "      <td>{'mse': 3.0433986724980326}</td>\n",
       "      <td>{'pearsonr': 0.6887357514969759}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>8.949191</td>\n",
       "      <td>{'mae': 2.3227810315069206}</td>\n",
       "      <td>{'mse': 3.002995513570945}</td>\n",
       "      <td>{'pearsonr': 0.6932091045154565}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.032724</td>\n",
       "      <td>{'mae': 2.308517244866657}</td>\n",
       "      <td>{'mse': 3.016077816052307}</td>\n",
       "      <td>{'pearsonr': 0.696391972906381}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.074909</td>\n",
       "      <td>{'mae': 2.327362372185373}</td>\n",
       "      <td>{'mse': 3.0232978330668776}</td>\n",
       "      <td>{'pearsonr': 0.6954025684814278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19.116300</td>\n",
       "      <td>9.183589</td>\n",
       "      <td>{'mae': 2.360814539914204}</td>\n",
       "      <td>{'mse': 3.041023617962829}</td>\n",
       "      <td>{'pearsonr': 0.6907320608720451}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.201824</td>\n",
       "      <td>{'mae': 2.3432669560921373}</td>\n",
       "      <td>{'mse': 3.043615451312719}</td>\n",
       "      <td>{'pearsonr': 0.6948231832872411}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.025446</td>\n",
       "      <td>{'mae': 2.3228368737975957}</td>\n",
       "      <td>{'mse': 3.0140064155325925}</td>\n",
       "      <td>{'pearsonr': 0.6953549231014581}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.181195</td>\n",
       "      <td>{'mae': 2.3440134885347432}</td>\n",
       "      <td>{'mse': 3.0367927274947375}</td>\n",
       "      <td>{'pearsonr': 0.6965630378833736}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.247084</td>\n",
       "      <td>{'mae': 2.3650319232855956}</td>\n",
       "      <td>{'mse': 3.0487592547706885}</td>\n",
       "      <td>{'pearsonr': 0.6981907800115251}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>8.921514</td>\n",
       "      <td>{'mae': 2.3003796072780784}</td>\n",
       "      <td>{'mse': 2.9946331421535852}</td>\n",
       "      <td>{'pearsonr': 0.6992992781844094}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.789267</td>\n",
       "      <td>{'mae': 2.4496620356053267}</td>\n",
       "      <td>{'mse': 3.136834178302483}</td>\n",
       "      <td>{'pearsonr': 0.6949700419946728}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.279521</td>\n",
       "      <td>{'mae': 2.366903531369824}</td>\n",
       "      <td>{'mse': 3.0537992199243904}</td>\n",
       "      <td>{'pearsonr': 0.6949304307010559}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.351927</td>\n",
       "      <td>{'mae': 2.3594782099808533}</td>\n",
       "      <td>{'mse': 3.065605674316842}</td>\n",
       "      <td>{'pearsonr': 0.6984262420356977}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.338190</td>\n",
       "      <td>{'mae': 2.388594435253724}</td>\n",
       "      <td>{'mse': 3.0628002947556343}</td>\n",
       "      <td>{'pearsonr': 0.7000122040510783}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>7.725700</td>\n",
       "      <td>9.328236</td>\n",
       "      <td>{'mae': 2.3904950119517174}</td>\n",
       "      <td>{'mse': 3.060215964311057}</td>\n",
       "      <td>{'pearsonr': 0.6971274231622173}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.459687</td>\n",
       "      <td>{'mae': 2.3979339540609854}</td>\n",
       "      <td>{'mse': 3.0812230876386244}</td>\n",
       "      <td>{'pearsonr': 0.6938951829303535}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.379081</td>\n",
       "      <td>{'mae': 2.3764319149068163}</td>\n",
       "      <td>{'mse': 3.0686860270465903}</td>\n",
       "      <td>{'pearsonr': 0.7010154745534819}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.015869</td>\n",
       "      <td>{'mae': 2.3296396040976957}</td>\n",
       "      <td>{'mse': 3.0084276799046714}</td>\n",
       "      <td>{'pearsonr': 0.7018540055302361}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.691763</td>\n",
       "      <td>{'mae': 2.413307456157837}</td>\n",
       "      <td>{'mse': 3.1189287785499458}</td>\n",
       "      <td>{'pearsonr': 0.6974769286561604}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.027360</td>\n",
       "      <td>{'mae': 2.309597572926337}</td>\n",
       "      <td>{'mse': 3.0098322386389116}</td>\n",
       "      <td>{'pearsonr': 0.7001927809052185}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>8.986550</td>\n",
       "      <td>{'mae': 2.3132132707059685}</td>\n",
       "      <td>{'mse': 3.0024720451133216}</td>\n",
       "      <td>{'pearsonr': 0.7048573106334318}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.340969</td>\n",
       "      <td>{'mae': 2.35367558964618}</td>\n",
       "      <td>{'mse': 3.061479014874914}</td>\n",
       "      <td>{'pearsonr': 0.7017535794165779}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.238797</td>\n",
       "      <td>{'mae': 2.3350426335322676}</td>\n",
       "      <td>{'mse': 3.0451576052657163}</td>\n",
       "      <td>{'pearsonr': 0.7042929563004063}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.316287</td>\n",
       "      <td>{'mae': 2.363551876644798}</td>\n",
       "      <td>{'mse': 3.056868949132607}</td>\n",
       "      <td>{'pearsonr': 0.7039081131066605}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>6.044700</td>\n",
       "      <td>9.174237</td>\n",
       "      <td>{'mae': 2.3621349071109963}</td>\n",
       "      <td>{'mse': 3.0328383393124208}</td>\n",
       "      <td>{'pearsonr': 0.7022118384456761}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.243540</td>\n",
       "      <td>{'mae': 2.350130192822006}</td>\n",
       "      <td>{'mse': 3.04461026509493}</td>\n",
       "      <td>{'pearsonr': 0.703702266835018}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.107644</td>\n",
       "      <td>{'mae': 2.3348493033329847}</td>\n",
       "      <td>{'mse': 3.021573759026676}</td>\n",
       "      <td>{'pearsonr': 0.7024921150308578}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.276208</td>\n",
       "      <td>{'mae': 2.362295166716963}</td>\n",
       "      <td>{'mse': 3.050009676266118}</td>\n",
       "      <td>{'pearsonr': 0.6973203254924087}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.287782</td>\n",
       "      <td>{'mae': 2.347234775061686}</td>\n",
       "      <td>{'mse': 3.0524878710804106}</td>\n",
       "      <td>{'pearsonr': 0.6964527075820495}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.549400</td>\n",
       "      <td>{'mae': 2.377128736754208}</td>\n",
       "      <td>{'mse': 3.0948740499886904}</td>\n",
       "      <td>{'pearsonr': 0.6999471141896372}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.699612</td>\n",
       "      <td>{'mae': 2.3979556559759954}</td>\n",
       "      <td>{'mse': 3.1186796399538252}</td>\n",
       "      <td>{'pearsonr': 0.6974756598017134}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.384116</td>\n",
       "      <td>{'mae': 2.3493667061861396}</td>\n",
       "      <td>{'mse': 3.0677020305852767}</td>\n",
       "      <td>{'pearsonr': 0.7027685464813993}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.508167</td>\n",
       "      <td>{'mae': 2.360549150687184}</td>\n",
       "      <td>{'mse': 3.0878260153294477}</td>\n",
       "      <td>{'pearsonr': 0.7016193963498668}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.370453</td>\n",
       "      <td>{'mae': 2.3341020393341325}</td>\n",
       "      <td>{'mse': 3.0648396061138112}</td>\n",
       "      <td>{'pearsonr': 0.7010686079945112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>9.444829</td>\n",
       "      <td>{'mae': 2.3474058292541407}</td>\n",
       "      <td>{'mse': 3.0774909250976705}</td>\n",
       "      <td>{'pearsonr': 0.7001758739969692}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.591140</td>\n",
       "      <td>{'mae': 2.3547948854526286}</td>\n",
       "      <td>{'mse': 3.100896768824271}</td>\n",
       "      <td>{'pearsonr': 0.7006854947819899}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.471670</td>\n",
       "      <td>{'mae': 2.3487068604545547}</td>\n",
       "      <td>{'mse': 3.081955709403308}</td>\n",
       "      <td>{'pearsonr': 0.6992249803326563}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.291784</td>\n",
       "      <td>{'mae': 2.32982664884347}</td>\n",
       "      <td>{'mse': 3.052056382500449}</td>\n",
       "      <td>{'pearsonr': 0.7013965706183167}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.318359</td>\n",
       "      <td>{'mae': 2.3293958732546285}</td>\n",
       "      <td>{'mse': 3.056293432995867}</td>\n",
       "      <td>{'pearsonr': 0.7015677535435958}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.769791</td>\n",
       "      <td>{'mae': 2.3802661517549892}</td>\n",
       "      <td>{'mse': 3.1290423095426085}</td>\n",
       "      <td>{'pearsonr': 0.7030188422055201}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.405684</td>\n",
       "      <td>{'mae': 2.323748347306917}</td>\n",
       "      <td>{'mse': 3.0706056590762527}</td>\n",
       "      <td>{'pearsonr': 0.7007308518192532}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.761126</td>\n",
       "      <td>{'mae': 2.3652448692751413}</td>\n",
       "      <td>{'mse': 3.1281012383823548}</td>\n",
       "      <td>{'pearsonr': 0.6959492412231449}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.887009</td>\n",
       "      <td>{'mae': 2.3800392670528536}</td>\n",
       "      <td>{'mse': 3.1477070227400623}</td>\n",
       "      <td>{'pearsonr': 0.6968307578711325}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.515741</td>\n",
       "      <td>{'mae': 2.3259085270429627}</td>\n",
       "      <td>{'mse': 3.0886146752365167}</td>\n",
       "      <td>{'pearsonr': 0.7013939955616622}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.757300</td>\n",
       "      <td>9.542128</td>\n",
       "      <td>{'mae': 2.3280086454552444}</td>\n",
       "      <td>{'mse': 3.092767520894838}</td>\n",
       "      <td>{'pearsonr': 0.7012074223215468}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.581423</td>\n",
       "      <td>{'mae': 2.33603851623871}</td>\n",
       "      <td>{'mse': 3.0991945424094363}</td>\n",
       "      <td>{'pearsonr': 0.701748021449031}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.484382</td>\n",
       "      <td>{'mae': 2.3321236422673093}</td>\n",
       "      <td>{'mse': 3.0836631419004954}</td>\n",
       "      <td>{'pearsonr': 0.6997079589745014}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.804646</td>\n",
       "      <td>{'mae': 2.344365758972649}</td>\n",
       "      <td>{'mse': 3.134801823537099}</td>\n",
       "      <td>{'pearsonr': 0.6989942852292466}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.421077</td>\n",
       "      <td>{'mae': 2.3077122384521562}</td>\n",
       "      <td>{'mse': 3.0730117733043096}</td>\n",
       "      <td>{'pearsonr': 0.7019254068305911}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.618938</td>\n",
       "      <td>{'mae': 2.3359459883103213}</td>\n",
       "      <td>{'mse': 3.104727419972373}</td>\n",
       "      <td>{'pearsonr': 0.6994819985688482}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.835649</td>\n",
       "      <td>{'mae': 2.3369759357709268}</td>\n",
       "      <td>{'mse': 3.139718420031501}</td>\n",
       "      <td>{'pearsonr': 0.6972219831062241}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.525572</td>\n",
       "      <td>{'mae': 2.298727283849934}</td>\n",
       "      <td>{'mse': 3.089937770577618}</td>\n",
       "      <td>{'pearsonr': 0.7003853760251756}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.492886</td>\n",
       "      <td>{'mae': 2.3048639005513363}</td>\n",
       "      <td>{'mse': 3.0845706810290525}</td>\n",
       "      <td>{'pearsonr': 0.6998125850710434}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.547711</td>\n",
       "      <td>{'mae': 2.3099118445380613}</td>\n",
       "      <td>{'mse': 3.0934349645883885}</td>\n",
       "      <td>{'pearsonr': 0.697459798517132}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>4.251600</td>\n",
       "      <td>9.629147</td>\n",
       "      <td>{'mae': 2.3159793726532594}</td>\n",
       "      <td>{'mse': 3.106501196599695}</td>\n",
       "      <td>{'pearsonr': 0.6972056268893643}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.657767</td>\n",
       "      <td>{'mae': 2.3275001645088196}</td>\n",
       "      <td>{'mse': 3.111073604278647}</td>\n",
       "      <td>{'pearsonr': 0.6952271912972139}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.636393</td>\n",
       "      <td>{'mae': 2.325280554176587}</td>\n",
       "      <td>{'mse': 3.1073856589991284}</td>\n",
       "      <td>{'pearsonr': 0.6967152645408616}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.627097</td>\n",
       "      <td>{'mae': 2.328884085120283}</td>\n",
       "      <td>{'mse': 3.105902444038613}</td>\n",
       "      <td>{'pearsonr': 0.6964338218063627}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.826002</td>\n",
       "      <td>{'mae': 2.3437672423643208}</td>\n",
       "      <td>{'mse': 3.1378257108950165}</td>\n",
       "      <td>{'pearsonr': 0.6961081725885742}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.975641</td>\n",
       "      <td>{'mae': 2.345466877229814}</td>\n",
       "      <td>{'mse': 3.1617113561591097}</td>\n",
       "      <td>{'pearsonr': 0.6951228339143329}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.782428</td>\n",
       "      <td>{'mae': 2.3280009022218926}</td>\n",
       "      <td>{'mse': 3.131057208214826}</td>\n",
       "      <td>{'pearsonr': 0.6959169161446859}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.605968</td>\n",
       "      <td>{'mae': 2.310864043833338}</td>\n",
       "      <td>{'mse': 3.102849155954282}</td>\n",
       "      <td>{'pearsonr': 0.6964006569563822}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.665035</td>\n",
       "      <td>{'mae': 2.310112590490259}</td>\n",
       "      <td>{'mse': 3.1122131456220217}</td>\n",
       "      <td>{'pearsonr': 0.6978453179971591}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.689495</td>\n",
       "      <td>{'mae': 2.311408796853523}</td>\n",
       "      <td>{'mse': 3.116122285309792}</td>\n",
       "      <td>{'pearsonr': 0.6986179505852237}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.873400</td>\n",
       "      <td>9.702282</td>\n",
       "      <td>{'mae': 2.3101722109438803}</td>\n",
       "      <td>{'mse': 3.1182730443567537}</td>\n",
       "      <td>{'pearsonr': 0.6987212107906897}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.731062</td>\n",
       "      <td>{'mae': 2.3209000513297955}</td>\n",
       "      <td>{'mse': 3.123066862477121}</td>\n",
       "      <td>{'pearsonr': 0.6952472225891833}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.700846</td>\n",
       "      <td>{'mae': 2.3242328784187434}</td>\n",
       "      <td>{'mse': 3.118043901590878}</td>\n",
       "      <td>{'pearsonr': 0.6969683680600293}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.624511</td>\n",
       "      <td>{'mae': 2.3125088291271085}</td>\n",
       "      <td>{'mse': 3.1058762252608507}</td>\n",
       "      <td>{'pearsonr': 0.6970438587415322}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.625125</td>\n",
       "      <td>{'mae': 2.308712564749161}</td>\n",
       "      <td>{'mse': 3.1059994795754355}</td>\n",
       "      <td>{'pearsonr': 0.6970012941906691}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.756313</td>\n",
       "      <td>{'mae': 2.3197846191032285}</td>\n",
       "      <td>{'mse': 3.1268265823186683}</td>\n",
       "      <td>{'pearsonr': 0.6982962069445007}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>10.014234</td>\n",
       "      <td>{'mae': 2.3434845647836093}</td>\n",
       "      <td>{'mse': 3.167713490710381}</td>\n",
       "      <td>{'pearsonr': 0.6977250192093101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.762125</td>\n",
       "      <td>{'mae': 2.320665801539639}</td>\n",
       "      <td>{'mse': 3.12768794659421}</td>\n",
       "      <td>{'pearsonr': 0.6984394606145229}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.845638</td>\n",
       "      <td>{'mae': 2.326795617865427}</td>\n",
       "      <td>{'mse': 3.140995300061067}</td>\n",
       "      <td>{'pearsonr': 0.6963133066961212}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.925434</td>\n",
       "      <td>{'mae': 2.3324306158698755}</td>\n",
       "      <td>{'mse': 3.1536810324432034}</td>\n",
       "      <td>{'pearsonr': 0.6949128467351646}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.870200</td>\n",
       "      <td>9.729504</td>\n",
       "      <td>{'mae': 2.3112832469686033}</td>\n",
       "      <td>{'mse': 3.122533409721344}</td>\n",
       "      <td>{'pearsonr': 0.6961713004588811}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.727352</td>\n",
       "      <td>{'mae': 2.3083533932109774}</td>\n",
       "      <td>{'mse': 3.1221790058176517}</td>\n",
       "      <td>{'pearsonr': 0.6965641653518091}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.770907</td>\n",
       "      <td>{'mae': 2.3157668168169594}</td>\n",
       "      <td>{'mse': 3.129166498501954}</td>\n",
       "      <td>{'pearsonr': 0.6966041680944239}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.683543</td>\n",
       "      <td>{'mae': 2.306163437172846}</td>\n",
       "      <td>{'mse': 3.115160616468005}</td>\n",
       "      <td>{'pearsonr': 0.6978246435396238}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.585687</td>\n",
       "      <td>{'mae': 2.2971693021694417}</td>\n",
       "      <td>{'mse': 3.0994052505983953}</td>\n",
       "      <td>{'pearsonr': 0.6992721838990339}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.640119</td>\n",
       "      <td>{'mae': 2.3007625809629557}</td>\n",
       "      <td>{'mse': 3.108144529726083}</td>\n",
       "      <td>{'pearsonr': 0.6987438169064326}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.647079</td>\n",
       "      <td>{'mae': 2.29867186196867}</td>\n",
       "      <td>{'mse': 3.1092311376886004}</td>\n",
       "      <td>{'pearsonr': 0.6988186770140167}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.567846</td>\n",
       "      <td>{'mae': 2.2916429899822033}</td>\n",
       "      <td>{'mse': 3.096487200391258}</td>\n",
       "      <td>{'pearsonr': 0.6991834499678364}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.647668</td>\n",
       "      <td>{'mae': 2.3000450132008132}</td>\n",
       "      <td>{'mse': 3.109335904321318}</td>\n",
       "      <td>{'pearsonr': 0.6987791730206905}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.657561</td>\n",
       "      <td>{'mae': 2.301509993103555}</td>\n",
       "      <td>{'mse': 3.110912917042376}</td>\n",
       "      <td>{'pearsonr': 0.6988123278401488}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.600100</td>\n",
       "      <td>9.683839</td>\n",
       "      <td>{'mae': 2.3040061715593194}</td>\n",
       "      <td>{'mse': 3.11513477777198}</td>\n",
       "      <td>{'pearsonr': 0.6985007066715654}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.626900</td>\n",
       "      <td>9.688581</td>\n",
       "      <td>{'mae': 2.3044655244362535}</td>\n",
       "      <td>{'mse': 3.1158897762872635}</td>\n",
       "      <td>{'pearsonr': 0.6985104669301789}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-1500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-2500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-3500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-4500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-5000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1/checkpoint-5000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=6.20960732421875, metrics={'train_runtime': 574.8886, 'train_samples_per_second': 137.244, 'train_steps_per_second': 8.697, 'total_flos': 726968128204800.0, 'train_loss': 6.20960732421875, 'epoch': 100.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c152ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#take care of distributed/paralelle training \n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model \n",
    "model_to_save.save_pretrained(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4fb37c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.109,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.144,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 464,\n",
      "  \"is_gpu\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 515,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"norm_mean\": [\n",
      "    11.199569164274653,\n",
      "    -0.9728601944583675,\n",
      "    11.199595401578872,\n",
      "    0.1914454376660732,\n",
      "    0.608589373135307,\n",
      "    365.064017672,\n",
      "    342.24912812000014,\n",
      "    364.6033136038417,\n",
      "    134.06547,\n",
      "    0.004249,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    1.1861084842221647,\n",
      "    1.890967178564785,\n",
      "    2.519587985439997,\n",
      "    2.0112818114267816,\n",
      "    795.5621221754437,\n",
      "    18.14439203724506,\n",
      "    14.536240385432393,\n",
      "    15.215140271072487,\n",
      "    12.068994414289726,\n",
      "    8.453657900068215,\n",
      "    9.114162139055054,\n",
      "    6.434168605708085,\n",
      "    7.215103879809845,\n",
      "    4.436200487997215,\n",
      "    5.109730699855831,\n",
      "    3.055231525907226,\n",
      "    3.6252747118486264,\n",
      "    -2.202564923376624,\n",
      "    18.195385007867852,\n",
      "    7.9706993589944775,\n",
      "    4.5379164631837545,\n",
      "    150.95250337667272,\n",
      "    13.184208966483704,\n",
      "    8.814008658052902,\n",
      "    3.8191839078987306,\n",
      "    3.4969386790830774,\n",
      "    2.9222201316693712,\n",
      "    2.644444123964607,\n",
      "    6.408740449956927,\n",
      "    4.95314480536345,\n",
      "    2.6263770771853108,\n",
      "    2.4113616526384853,\n",
      "    26.24052195128434,\n",
      "    37.102909834641714,\n",
      "    19.89943953042712,\n",
      "    16.353848799228413,\n",
      "    15.638332143998122,\n",
      "    21.706094849865753,\n",
      "    0.28727529762970366,\n",
      "    8.054432014422119,\n",
      "    3.2648099385428853,\n",
      "    32.629006626588726,\n",
      "    16.26551059790217,\n",
      "    47.70605007162041,\n",
      "    0.0,\n",
      "    5.325837027308287,\n",
      "    9.698460925314944,\n",
      "    5.573601891254677,\n",
      "    2.581492771453006,\n",
      "    7.3124961943884665,\n",
      "    33.07539073817076,\n",
      "    10.718462271839512,\n",
      "    6.99277406210818,\n",
      "    31.684923475431933,\n",
      "    36.92162447084414,\n",
      "    1.2074202610211657,\n",
      "    5.110701506051421,\n",
      "    0.0,\n",
      "    71.04050338999998,\n",
      "    9.57750975344203,\n",
      "    10.066085526965992,\n",
      "    0.07691213090851719,\n",
      "    13.38923196114951,\n",
      "    16.862422387837878,\n",
      "    21.382953923695233,\n",
      "    15.651918121909311,\n",
      "    14.440634953378058,\n",
      "    19.13130604146014,\n",
      "    22.114944705243296,\n",
      "    8.183429061888226,\n",
      "    13.699768012021506,\n",
      "    2.1212691930096144,\n",
      "    17.474216494453906,\n",
      "    7.8467696174922725,\n",
      "    2.6683841482907034,\n",
      "    0.11868201225906093,\n",
      "    9.064881467380093,\n",
      "    2.659801877718109,\n",
      "    4.055917032498944,\n",
      "    0.259848432909807,\n",
      "    0.413963629624058,\n",
      "    25.186704,\n",
      "    1.79722,\n",
      "    5.353545,\n",
      "    0.272499,\n",
      "    0.562898,\n",
      "    0.835397,\n",
      "    1.236854,\n",
      "    0.729917,\n",
      "    1.966771,\n",
      "    4.216321,\n",
      "    1.414081,\n",
      "    6.486208,\n",
      "    5.688314,\n",
      "    0.205632,\n",
      "    0.409204,\n",
      "    0.614836,\n",
      "    2.802168,\n",
      "    2.7549044689500004,\n",
      "    97.31541557350002,\n",
      "    0.069051,\n",
      "    0.151924,\n",
      "    0.130758,\n",
      "    0.06279,\n",
      "    0.027038,\n",
      "    0.999062,\n",
      "    0.096951,\n",
      "    0.042862,\n",
      "    0.096089,\n",
      "    0.100163,\n",
      "    1.033857,\n",
      "    1.034286,\n",
      "    0.016206,\n",
      "    0.00357,\n",
      "    0.016776,\n",
      "    1.488795,\n",
      "    0.915699,\n",
      "    0.232236,\n",
      "    0.012241,\n",
      "    0.074885,\n",
      "    0.131561,\n",
      "    0.096951,\n",
      "    0.004026,\n",
      "    0.009835,\n",
      "    0.011646,\n",
      "    0.250196,\n",
      "    0.131237,\n",
      "    0.768633,\n",
      "    0.015927,\n",
      "    0.539599,\n",
      "    0.451885,\n",
      "    0.001726,\n",
      "    0.003335,\n",
      "    0.001218,\n",
      "    1.236474,\n",
      "    0.000226,\n",
      "    0.555529,\n",
      "    0.000149,\n",
      "    0.001046,\n",
      "    0.002578,\n",
      "    0.126995,\n",
      "    0.732216,\n",
      "    0.037978,\n",
      "    0.019179,\n",
      "    0.720141,\n",
      "    0.018951,\n",
      "    0.013025,\n",
      "    0.059523,\n",
      "    0.027553,\n",
      "    0.000831,\n",
      "    0.0002,\n",
      "    0.073914,\n",
      "    0.061694,\n",
      "    0.002249,\n",
      "    0.007716,\n",
      "    0.236426,\n",
      "    0.0287,\n",
      "    0.05231,\n",
      "    0.041425,\n",
      "    0.033421,\n",
      "    0.017275,\n",
      "    0.001082,\n",
      "    0.011915,\n",
      "    0.004249,\n",
      "    0.196769,\n",
      "    0.039316,\n",
      "    0.038686,\n",
      "    0.00409,\n",
      "    0.003615,\n",
      "    0.116124,\n",
      "    0.051192,\n",
      "    0.025177,\n",
      "    0.0,\n",
      "    0.161908,\n",
      "    0.315775,\n",
      "    0.087229,\n",
      "    0.079586,\n",
      "    0.023227,\n",
      "    0.005966,\n",
      "    0.007901,\n",
      "    0.050376,\n",
      "    0.000186,\n",
      "    0.065723,\n",
      "    0.380193,\n",
      "    0.051566\n",
      "  ],\n",
      "  \"norm_std\": [\n",
      "    2.9210526350021033,\n",
      "    1.5294133532822065,\n",
      "    2.9209947673330334,\n",
      "    0.21956154740898992,\n",
      "    0.22097666681598954,\n",
      "    160.48566423804579,\n",
      "    151.38170855657367,\n",
      "    160.3304390667665,\n",
      "    60.484857692625106,\n",
      "    0.181038611279414,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.24851193112366385,\n",
      "    0.317494124851492,\n",
      "    0.37175815103599535,\n",
      "    0.6098706561111424,\n",
      "    539.8195290502504,\n",
      "    8.140940922894863,\n",
      "    6.600767667198695,\n",
      "    6.700942921964325,\n",
      "    5.536318526756788,\n",
      "    4.020569431789569,\n",
      "    4.316039675035455,\n",
      "    3.229701298304296,\n",
      "    4.058753110098356,\n",
      "    2.399274478688092,\n",
      "    4.590084765547685,\n",
      "    1.8657465201411236,\n",
      "    8.197075845395899,\n",
      "    1.3989800795766576,\n",
      "    8.727770321711972,\n",
      "    4.719034225006412,\n",
      "    3.6844834579923407,\n",
      "    66.65125255607474,\n",
      "    11.022808176926917,\n",
      "    9.88512023443511,\n",
      "    5.895101555004671,\n",
      "    6.0315631910071374,\n",
      "    4.465786134186721,\n",
      "    8.73293454096314,\n",
      "    7.292192943139112,\n",
      "    5.798809757257198,\n",
      "    5.458840154330179,\n",
      "    5.34562222799046,\n",
      "    28.624753237838462,\n",
      "    22.7685485030176,\n",
      "    13.735506972569182,\n",
      "    12.75558914023291,\n",
      "    12.647297666063738,\n",
      "    16.73803715869515,\n",
      "    1.3236865505015507,\n",
      "    8.012917117258175,\n",
      "    6.328266302270954,\n",
      "    30.80439768300023,\n",
      "    14.510669158473307,\n",
      "    33.76748799216324,\n",
      "    0.0,\n",
      "    8.851153866015428,\n",
      "    8.222102882220607,\n",
      "    7.329351085680612,\n",
      "    4.87773057457412,\n",
      "    10.796349487508557,\n",
      "    24.55359833254403,\n",
      "    10.33295824604808,\n",
      "    8.986884190324291,\n",
      "    26.77991276665104,\n",
      "    29.521288543995215,\n",
      "    4.077418430037268,\n",
      "    11.23487898363004,\n",
      "    0.0,\n",
      "    50.277243284807206,\n",
      "    19.12173183245714,\n",
      "    9.819697177666312,\n",
      "    1.4201437981599128,\n",
      "    12.511435257208836,\n",
      "    14.212538029397628,\n",
      "    16.973978925056553,\n",
      "    19.21649041911615,\n",
      "    15.092240504961104,\n",
      "    19.889237093009676,\n",
      "    25.80872442073538,\n",
      "    9.254317550453825,\n",
      "    19.013243564373347,\n",
      "    3.6841568734614953,\n",
      "    17.690679185577395,\n",
      "    10.27595457263499,\n",
      "    3.3283202642652645,\n",
      "    2.8773795244438474,\n",
      "    9.228734822190495,\n",
      "    5.106296483962912,\n",
      "    4.008127533955226,\n",
      "    2.3345092198667503,\n",
      "    0.23958883840178574,\n",
      "    11.48532061063049,\n",
      "    2.0042680181777808,\n",
      "    3.411142707197923,\n",
      "    0.7103265443180337,\n",
      "    0.8009597262862117,\n",
      "    1.0630493791282618,\n",
      "    1.2495037990913607,\n",
      "    0.8592211073826755,\n",
      "    1.4909738617970663,\n",
      "    2.8049912821495706,\n",
      "    1.5692082041123125,\n",
      "    3.7188860712382157,\n",
      "    4.918753910447648,\n",
      "    0.6213838320183964,\n",
      "    0.6971589290933399,\n",
      "    0.9385507839118636,\n",
      "    1.7370945619837506,\n",
      "    2.7759468746763334,\n",
      "    43.91556441471313,\n",
      "    0.2929625321198007,\n",
      "    0.6742399816263887,\n",
      "    0.6447563579731193,\n",
      "    0.26136083143708466,\n",
      "    0.1703202147866646,\n",
      "    1.3696411924562566,\n",
      "    0.3394696140137124,\n",
      "    0.26977939457438505,\n",
      "    0.3350074869447194,\n",
      "    0.3408584597974497,\n",
      "    1.2690580420372088,\n",
      "    1.2684116362885036,\n",
      "    0.1297126917051003,\n",
      "    0.06304965563156611,\n",
      "    0.17914965229828922,\n",
      "    1.485673805113914,\n",
      "    1.1656052934139842,\n",
      "    0.5018632205797633,\n",
      "    0.15576643470973517,\n",
      "    0.2883562378800223,\n",
      "    0.3774901929558512,\n",
      "    0.3394696140137124,\n",
      "    0.07983606764988928,\n",
      "    0.10307416455777559,\n",
      "    0.11692041889415362,\n",
      "    1.0010868912132271,\n",
      "    0.7705779932112281,\n",
      "    1.157481598590082,\n",
      "    0.13507534533122212,\n",
      "    0.8359812306885952,\n",
      "    0.7600865243553028,\n",
      "    0.04757124327808961,\n",
      "    0.07183232513905516,\n",
      "    0.03513570421263404,\n",
      "    1.239225396368063,\n",
      "    0.015097985029438593,\n",
      "    1.3364349277900949,\n",
      "    0.013378265133341392,\n",
      "    0.032663541616103894,\n",
      "    0.060970137226002974,\n",
      "    0.44400840883756576,\n",
      "    1.159532265122051,\n",
      "    0.198246590935912,\n",
      "    0.1491817288215558,\n",
      "    1.28126795861232,\n",
      "    0.143114919141507,\n",
      "    0.11579880303510387,\n",
      "    0.25012811724209466,\n",
      "    0.1830406121462275,\n",
      "    0.03504726333553974,\n",
      "    0.015295758691880374,\n",
      "    0.3034514997274073,\n",
      "    0.2749689545601939,\n",
      "    0.04859983910409953,\n",
      "    0.09878498419533764,\n",
      "    0.5707110234042025,\n",
      "    0.17028898672063034,\n",
      "    0.24456026600763192,\n",
      "    0.21322057789532142,\n",
      "    0.1917343827305721,\n",
      "    0.13591391704896466,\n",
      "    0.03519702423260403,\n",
      "    0.11080182783711219,\n",
      "    0.0680510883818226,\n",
      "    0.5264724473438641,\n",
      "    0.2602735481879015,\n",
      "    0.25847912916802446,\n",
      "    0.10886360159063149,\n",
      "    0.10026934640727359,\n",
      "    0.35113436163289397,\n",
      "    0.2260341350934195,\n",
      "    0.16874580630684471,\n",
      "    0.0,\n",
      "    0.4146998571400424,\n",
      "    0.5347143492505464,\n",
      "    0.3137422508894841,\n",
      "    0.27962501103110715,\n",
      "    0.1547563582555832,\n",
      "    0.08130444916739461,\n",
      "    0.08949068223889126,\n",
      "    0.22530492534853602,\n",
      "    0.014421012861987593,\n",
      "    0.2736413019822887,\n",
      "    2.253629375384596,\n",
      "    0.22817317920167496\n",
      "  ],\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 600\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at C:/Users/pj11/Documents/bert_finetune2/hansen_p_fold1//model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making prediction \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_output_path)\n",
    "\n",
    "# arguments for Trainer\n",
    "test_args = TrainingArguments(\n",
    "     output_dir =model_output_path,\n",
    "     do_train = False,\n",
    "     do_predict = True,\n",
    "     dataloader_drop_last = False\n",
    ")\n",
    "\n",
    "# Init Trainer\n",
    "trainer=Trainer(\n",
    "          model = model,\n",
    "          args = test_args,\n",
    "          compute_metrics = compute_metrics)\n",
    "\n",
    "test_results = trainer.predict(small_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27ef5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.9,  0. ,  0.8,  0. ,  2.2,  7.3, 18.8,  1.8,  9. ,  1.7,  0.6,\n",
       "        4.1,  1.7, 18. ,  7.1,  4.1,  5.4,  9.7,  7. , 14. ,  6.9,  7. ,\n",
       "        7. ,  4.7, 15.5, 14.8,  4.7,  6.5, 15.3, 11. ,  1. ,  5.1, 19.8,\n",
       "        1.6,  7.9,  7.6,  4.9, 10.6,  7.2,  7. ,  6.3,  5.9,  9.9,  6.1,\n",
       "        3.3,  4.1,  9.9,  6.1,  5.7,  4.8,  7.2, 20.5,  8.5,  5.2, 10.4,\n",
       "        9.6,  0. ,  6.1,  0. ,  7.9,  6.5,  4.1,  3.9,  7.6,  8. ,  8.9,\n",
       "        0. , 10.6,  9.2,  7.5,  4. ,  3.4,  8.7, 17.4,  2. ,  6.8,  5.6,\n",
       "       10.3, 10. ,  4.9,  4.3,  0. ,  8.9,  9.3,  7.5,  4.3, 15.5,  5. ,\n",
       "       13.1, 12.5,  2.6,  6. ,  6.4,  8.1,  3.7,  8.5,  6.2,  9.1,  9.2,\n",
       "        7. ,  9.2,  8.4,  4.3,  5. ,  8.2,  8.7,  6.1,  4.6, 12.8,  8. ,\n",
       "       16. , 13.7,  1. ,  0.1,  8.8,  6.9,  5.5, 10.3,  7.7,  7.6,  1.8,\n",
       "       16.7,  4.9,  6.2,  3.1,  0. ,  6.2,  4.4,  0. ,  1.6, 10.3,  7.6,\n",
       "        0.1,  1.7,  0. ,  2.4, 11.2, 10.7,  4.2, 19.5, 12.4,  1.8,  3.4,\n",
       "       16.2,  0. , 11.3,  3.7,  6.1,  3.1,  6.5,  5.3,  1.8,  7.6,  6.2,\n",
       "        9.8,  1.7,  6.1,  8.1, 16.8,  6.3,  1.3,  9.9,  5.6,  2.9,  8.8,\n",
       "        0. , 10. ,  9.2, 11.3,  1. ,  6.3,  1.2, 13.1,  5.7,  8.4, 17.6,\n",
       "       11. ,  0. ,  4.9,  4.3,  5.5,  9.3,  8.2, 13.6, 12.3,  3.7,  0. ,\n",
       "        6.5,  4.5,  7.1,  6.6,  6.5, 11.3,  3.7,  7.4, 11.2,  3.7],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out prediction in test set\n",
    "test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09656a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 11.0779390335083,\n",
       " 'test_mae': {'mae': 2.2994369157982355},\n",
       " 'test_rmse': {'mse': 3.328163097223352},\n",
       " 'test_pearsonr': {'pearsonr': 0.7043356767778755},\n",
       " 'test_runtime': 0.8898,\n",
       " 'test_samples_per_second': 221.394,\n",
       " 'test_steps_per_second': 7.867}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out metric in test set\n",
    "test_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362ec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.299437\n",
      "3.3281631109356953\n",
      "0.33353279924017853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "# MAE, AE and RMSE give an idea of the error distribution\n",
    "print(mean_absolute_error(test_results[0], test_results[1]))\n",
    "\n",
    "#RMSEs\n",
    "print(math.sqrt(mean_squared_error(test_results[0], test_results[1])))\n",
    "\n",
    "# R^2 Coefficient of Determination\n",
    "print(r2_score(test_results[0], test_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef967db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred. Hansen p')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1P0lEQVR4nO3deXxU5fX48c9JCBoUiGhEjLKoCLZiQUGo0FZcwErVCCJurUsrWLe6YbE/Faz6hYoVv3VpcaeKuKERV/QrIIqVCoIim7aKSEBlVRAIITm/P+5MmCT3ztxZbmY779eLF8nNzNznziTn3vs85zmPqCrGGGPyR0G6G2CMMaZpWeA3xpg8Y4HfGGPyjAV+Y4zJMxb4jTEmzzRLdwP82GeffbRjx47pboYxxmSV+fPnr1PV0obbsyLwd+zYkXnz5qW7GcYYk1VE5Eu37dbVY4wxecYCvzHG5BkL/MYYk2cs8BtjTJ4JLPCLyIEiMlNElorIYhH5Q2j7GBGpFJGFoX8nB9UGY4wxjQWZ1bMTuFZVPxSRlsB8EXkz9LMJqnpngPs2xhjjIbDAr6prgDWhrzeLyFKgLKj9GWOM8adJ+vhFpCPQA5gb2nS5iHwsIo+IyF4ezxkuIvNEZN7atWubopnGGJM51q2Dr78O5KUDD/wisicwFbhKVb8H/g4cDHTHuSP4q9vzVPUBVe2pqj1LSxtNPDPGmNx25ZVw2WWBvHSgM3dFpAgn6E9W1ecBVPWbiJ8/CLwcZBuMMSZrLF8Ou+8OHTrA2LGwZUsguwkyq0eAh4GlqnpXxPZ2EQ87HfgkqDYYY0xWqKqCMWPgiCPg+uudbR06wI9/HMjugrzi7wv8GlgkIgtD2/4EnC0i3QEFVgAjAmyDMcZktlmzYMQI+PRTOOccuOuumE9JVpBZPe8C4vKjV4PapzHGZJXHH4ff/AYOOgimT4cBA5pktzZz1xhjmpIqfPut8/Wpp8Kf/wyffNJkQR8s8BtjTNNZvhyOOw5OOAGqq6F1a7jpJigubtJmWOA3xpigVVXBLbc4g7cLF8Lll0NhYdqakxULsRhjTNZasQIGDnQGb88+GyZMgLZt09okC/zGGBOE2looKICyMjjsMPjb35wTQAawrh5jjEklVZg0Cbp3h02boKgIKioyJuiDBX5jjEmd8ODtBRdAy5ZO4M9AFviNMSZZNTX1B28nToR33oGOHdPdMlfWx2+MMckqKIC5c2HIEGfm7X77pbtFUdkVvzHGJGLdOhg+HL74AkTghRfgySczPuiDBX5jjIlPePC2a1d49FF4911n+267pbddcbDAb4wxfi1fDscf7wzedukCCxbAr3+d7lbFzfr4jTHGr3vvhQ8/dAZvf/c7p28/C2Vnq40xpqnMmgXz5jlf33YbLFvm9O1nadAHC/zGGONu3Tq46CLo3x9uvdXZ1rp1VgzexmKB3xhjIkUO3j7+ONxwA0yZku5WpZT18RtjTKQnn3QGb485xunLP/zwdLco5SzwG2NMVZVTPbNbNzjzTCcv/6yzsrofP5rcPCpjjPFr1iyn1MKAAbB1q1NU7ZxzcjbogwV+Y0y+WrcOLrzQGbytrobHHoMWLdLdqiZhXT3GmPyzciUceSR89x2MGuUsf5gnQR8s8Btj8snmzU655AMPhIsvdrp0unVLd6uanHX1GGNyX1UV/PnP0KHDrqJqY8fmZdAHu+I3xuS6t9+GESOcOjtnnZVXXTpe7IrfGJObamudejrHHgs7dsDrrzsTsdK80HkmsMBvjMlNBQWwxx7O4O0nn2TUmrfpZoHfGJM7Pv0UTjgB/vUv5/u773b68q17px4L/MaY7FdV5ax5262bU0lz9Wpnu0h625WhbHDXGJPdZs92yiSHB28nTMiJCppBCuyKX0QOFJGZIrJURBaLyB9C29uIyJsi8lno/72CaoMxJg/MnesM3r72mjN4a0E/piC7enYC16rqYUAf4DIR+REwCnhLVTsDb4W+N8YYf1Thn/+EF190vr/qKmfw9qST0tqsbBJY4FfVNar6YejrzcBSoAw4DZgUetgkoDyoNhhjckx48Pb8853gD05RNRu8jUuTDO6KSEegBzAXaKuqa8A5OQD7ejxnuIjME5F5a9eubYpmGmMyVXjmbbduMH8+/P3v8Oyz6W5V1go88IvInsBU4CpV/d7v81T1AVXtqao9S0tLg2ugMSbzvf46jB4Ngwc7a95ecklOl00OWqDvnIgU4QT9yar6fGjzNyLSLvTzdsC3QbbBGJOl1q93BmwBTj3VGcS1wduUCDKrR4CHgaWqelfEj6YB54e+Ph94Mag2GGOyUHjwtmtXJz3z+++dfPyjj053y3JGkFf8fYFfA8eJyMLQv5OBccCJIvIZcGLoe2OMqT9427kzvPsutGqV7lblnMAmcKnqu4DXtLnjg9qvMSZLff01dO8OzZs7g7fDh1s/fkBs5q4xJr3+8x845BCn7/7++518fOvHD5SdTo0x6bF+PVx0EXTp4gzcAlxwgQX9JmBX/MaYpqUKjz8O114LmzbByJF5uxJWuljgN8Y0HVUnNfPll+GnP4WJEy3op4EFfmNM8HbscEoriDh9+IMG2eBtGtm7bowJ1ttvwxFH7CqxcNllNvM2zeydN8YEIzx4G17zdu+9090iE2KB3xiTelOnOjNvH39815q3x9v0nUxhffzGmNSrqXFm3trgbUaywG+MSV5VFdxxB7Rs6SyMMnQonHGG9eNnKPtUjDHJefttp9TCzTfDokXONhEL+hnMPhljTGIiB2+3b4dXX4WHH053q4wPFviNMfFThc8+g8mT4Y9/hMWL4Ze/THerjE/Wx2+M8e/TT+GNN+Dyy6FPH1ixAtq1S3erTJzsit8YE1vkmrc33wwbNjjbLehnJQv8xpjowoO34TVvlyyBNm3S3SqTBOvqMcZ4W7/eqatTWuoM3lo/fk6wK35jTH2qMH268//ee8Mrr9jgbY6xwG+M2SW85u1JJ8HrrzvbfvELaNGi3sMqFlTSd9wMOo16hb7jZlCxoDINjTWJytmunooFlYyfvpzVm7axf0kxIwd2obxHWbqbFVO2tjsV3I4dyLn3IyM/46oq+Mtf4PbbobjYWQJx4EDXh1YsqOSG5xexrboGgMpN27jheWfilp/jiPf4M/L9ynKiqrEfJDIY6Aco8K6qvhB0wyL17NlT582b5/vxDX8xAYqLChk7uFtG/8Jka7tTwe3YiwoEBKprdv2OZvv7kbGf8XHHwcyZMGwYTJgQNVun77gZVG7a1mh7WUkxc0YdF3U38R5/xr5fWUJE5qtqz4bbY3b1iMj9wCXAIuATYISI3Jf6JqbO+OnL6/2iAGyrrmH89OVpapE/2druVHA79uparRf0Ifvfj4z6jDdsgOpq5+trr3UGb596KmaK5mqXoB9te6R4jz+j3q8c4qeP/xfAQFV9VFUfBU4Gjg20VUlK5hcznbK13akQzzFm8/uREZ9xeM3bLl3grrucbYMG+R683b+kOK7tkeI9/ox4v3KQn8C/HGgf8f2BwMfBNCc1kvnFTKdsbXcqxHOM2fx+pP0zDg/e/uY3cMghcPLJcb/EyIFdKC4qrLetuKiwbkwmmniPP+3vV47yE/j3BpaKyCwRmQUsAUpFZJqITAu0dQlK5hcznbK13angduxFBUJRodTblu3vR1o/40cecZZAnD8f/v53mDMnoVr55T3KGDu4G2UlxQhO377fPvd4jz+f/yaC5Cer5+bAW5Fi4V/AbMsEyNZ2p4LXsbttS/b9aJgl0r9rKTOXrW2S9zwtn3FtrVMi+Uc/gvLymIO3fpT3KEuozfEefz7/TQTJV1ZPusWb1WOMF7cskYb8ZI1kRYrh+vVw/fWw++5wX0bnY5iAJJzVY0wuccsSaShW1kj45FG5aRvKrjz2TJjEVLGgkr5j3+LqU65jY4dDqJ00CVq3dgZ0jQmxwG/yit9skGiPy9QUw4oFldzzyP/xl4nXMuHlv/JF67acftE9VAy9zFkRy5iQwAK/iDwiIt+KyCcR28aISKWILAz9iz+lwJgk+M0Gifa4TE0xHD99OVXVO+m8/iv+34BLGXLeeD5q0z7tJySTeWIO7opIX2AM0CH0eAFUVQ+K8dTHgHuBfzbYPkFV74y7pcakwMiBXXz18UfLGtm/pNh15mo8KYYpHSOYPRuee47VxQPQkv342YiH2dGsqO7H6T4hmczj54r/YeAunJINvYCeof+jUtXZwIakWmdMirmlIp7Xp31cqYnJphimbIxg/Xr43e+cImovvcSPm20HqBf0wXLeTWN+0jm/U9XXUrjPy0XkN8A84FpV3ej2IBEZDgwHaN++vdtDjElIoqmIkc+HxFMMo40R+HoNVXjiCbjmGti40Vnz9uab+d3yja51bbIt5z0rMqayXMx0ThEZBxQCzwNV4e2q+mHMFxfpCLysqoeHvm8LrMMp9nYr0E5VL4r1OpbOaXJJp1Gv4PZXJ8AX4wbFfoHNm+HQQ6FjR5g40ZmUFZLtQTPRomzZftxB8Urn9HPF3zv0f+STFYhehs+Fqn4T0aAHgZfjfQ1jGsq2P/qExgh27IAHH4Thw6FlS3j3XejUyZmYFSHZu5l0S+RuKNky0fkoZuBX1f6p2pmItFPVNaFvT8ep9mlMwsE7G//o3QaYo3bJzJ4Nl1wCS5dCWZkz+/bgg5umsU0skYyppLvO8pCfssxtReRhEXkt9P2PROS3Pp43BfgX0EVEVoWec4eILBKRj4H+wNVJtt/kgGQGOzM1pz4a37VuIgdvt21zlkAsL09Hk5tMIkXZMjW9NpP56ep5DHgU+H+h7z8FnsbJ9vGkqme7bI76HJOfkrliy9Y/el9dMsOGwaxZTtmF0aMbLX+YqEzuGov7bojUpNfmGz+Bfx9VfUZEbgBQ1Z0iEn3OuzFxSCZ459wf/WefQWkplJTAnXc6ffgRg7exxArqmd41lkjGVCIni3znJ/D/ICJ74wzoIiJ9gO8CbZXJK8kE75z5o6+qgvHj4bbbnP78u++G7t3jegk/QT0b+sPjHaC2Cp7x8xP4rwGmAQeLyBygFDgj0FaZvJJM8M6JP/rIwduhQ528/AT4CerR7q4yuQsolmzPZmpqfrJ6PhSRXwBdcFKNl6tqdeAtM3kj2eCd1X/0994LV1wBHTo4g7cJrIgV5qfLzOvuqqRFUUZ3AZnU8lOrZyjwuqouFpEbgSNF5DY/E7iM8Surg3e8VGHLFicff9AgqKyEG2+EPfZI6mX9dJl53V2pkvFdQCZ1/NTquUlVN4tIP2AgMAn4e7DNMiZHffYZnHginHWWcwLo1AnGjqXi0030HTeDTqNeoe+4GQnV9vdTQ8grlfS7be438ZmeHWUS46ePP3wZMAj4u6q+KCJjgmuSMTloxw644w5n8Ha33WDs2LofpSrTxm+Xmdvd1fjpy3MrO8pE5SfwV4rIROAE4C8ishu2gItxkc2Dg4FatgwGD3YGb88801nzdv/9636cykybRLvMciY7yvjiJ/CfCZwE3Kmqm0SkHTAy2GaZppSKgJ3p+eFB8fXe7befk5fvMXibikloyX6GOZEdZXzzk9WzVUReBNqKSLg+8rJgm2WaSqoCdjbkh6ea53unSvmSWfDYY/Daa07QnzPHc/nDZCehpbKrKFc/K1Ofn1o9VwDfAG8Cr4T+WVXNHJFMrZuKBZV1A5JugQtye3DQ7b3b99uvKBt2Gvz6107mzrp1zg+irHmb7MIu2VivyKSXn66ePwBdVHV90I0xTS/Rbga3uulucnlwMPI9alazkxFzp3Lle09RVVgE99/vlFAuLIzyCo5ku1mytV6RSR8/gf8rrERDzkq0m8HtKrOhbBgcTKZvvOF796tl7/Bm5z48cPoVTPv90LjakUw3S87VKzKB85Od8zkwS0RuEJFrwv+CbphpGol2M0S7mvS7dm26Jbv27Z/67MstMx+i1fYt7CxsxtBz72DkGX/ioqHHBNvwBpLtKjL5x88V/8rQv+ahf8aHbEltTLSbwesqs6ykmDmj4l6cLS28+sbHTFsc/fhVYfJkBl1zDbUbNrD00B48XXYUrdvunZbP2TJyTLxirrmbCbJtzd1E1w3NJrlwjF5r3wLcPay7+3F89hn8/vfw1lvQuzc88EBcZZONaUpea+76yeopFZHxIvKqiMwI/wummbkhH7IsfK8ilcGi9YF7flbXXw8ffAD33eekaFrQN1nIT1fPZJwVt34FXAKcD6wNslHZLl+yLLI973vkwC5c9fRC15/V+6zeeQcOOMCpq3PPPU6mTrt2TdNIYwLgJ/DvraoPi8gfVPVt4G0ReTvohmUzy7IInt8xlETHWvYvKYYNG5wr/IcfhgsvhEcegQMOcF5z0gzrTzdZy0/gD5ftWyMig4DVwAHBNSn7Wd2T6JId+PY7UzXW47y6c0SV/61ZDF3PcoL/ddfBmDFx7duYTOYn8N8mIq2Ba4F7gFbA1YG2KstZloW3VAROv+UhYj3Oq+vtgvnT6PnWg87g7Ztvwk9+Eve+w8dqvwMmE/mp1RMuz/Ad0D/Y5uSObO//Dkoqavr4HUOJ9bjILrmimmr23bKRytb78l7fX8GwXnDRRY1m3vrdt90ZmEzmGfhF5B7wzHZDVa8MpEUmpyU78F2xoJICEWpc0pAbjqHEGmsJd8kd/vlH/M/0+9hZUMgZF9/L78uPAo/g7Hf8Jh+L1pnsEe2KPzJx/hZgdMBtMTmoYXdHSYsiNm5tvNqTn4Hv8FW0W9B3G0OJNdZS3qGY7p9MomPFU6xqtS93n/4Hbj/DI3/f52uGZWtml3VP5QfPwK+qk8Jfi8hVkd8b44dbd0dRgVBUKFTX7Arefge+veoDFYq4ziGIOtayeDH070/HDRtg5EgOGD2aO32seet3/CYbM7uS7Z6yk0b28DO4C1G6fEx+ieeP2y1QV9cqJcVF7LFbs7gDhNfVcq2q5/MbjbXs2OH8f+ihzkLnV11Vb/DWDz/jN9mY2ZVM95SNaWQXv4Hf5LB4cuLj+eP2CtTfbatm4egBcbczqavoHTtg/HgnJ//DD53FUR59NO42RNPwfRxyVBkzl63NmivgZLqnbEwju0Qb3N3Mriv9FiLyffhHgKpqq6AbZ4IXTzCP9487FStLRQbS/l1LmTq/sl4bBOjftTTq88aVbuJnf73RWfN26FCobjzGkCy393Hq/MqsKmORzOeVrWMa+cqzVo+qtlTVVqF/zSK+bmlBP3fEU1co3j/uZMoFVyyoZORzH9Urmfz0B19xZPvWRK5lpcDU+ZV1pZQjSy0X7azm8il/4We/G8LWTZvh5ZfhmWegtNRtl0nJhfpMyXxeXieHTB7TyGd+6vGbHBZPMI/3jzuZQm63vLS43gAwQHWN8t7nGxoNOEUG2MgAvKOwGfts3cTEowdzyiX/cPr0A5ILV7zJfF62JkB2CayPX0QewSns9q2qHh7a1gan4FtHYAVwpqpuDKoNJrZ4bu8TGbBMdCKbW8onOKXw3YQDbNEX/+XBGQ9xy/HDWVWyH8MH34hKAWyNuwlxycYsHjeJfl42Wz27BHnF/xhwUoNto4C3VLUz8Fboe5NG8VypZXIp5mY11Tww4CKmP3IZvVd+Quf1XwE4QR9nLMDvylqJsCte5/djzqjj+GLcIOaMOi4jfi+Mu8Cu+FV1toh0bLD5NODY0NeTgFnAH4PYv+UU+xPvlVpTlaIoLipgW3Vto+1FBdCssLDeXUfPVYsZ+/q9dF7/Fa927ceY4y7m25Z713ueQqAZJnbFa7JJQoFfRB5Q1eEJPLWtqq4BUNU1IrJvlH0MB4YDtG/fPq6dWE5xfDKxrtDuRYWugX/P3YsYfcqPGT99eV3XymlL3qa4uooLzxjNzIN7eb5m0P3tmfg+GuMm0a6eiSlthQtVfUBVe6pqz9I4szByIcMi323y6OPfuLWa8u77M+fANfRY7Xye435xASf+9v6oQR+yr7/dmKAkFPhVdX6C+/tGRNoBhP7/NsHXiSoXMizynVeQ7rhxNd/+9Bdw3nn8bskbAPywWwu2Nd+97jElxUV5399uTDTRJnC9RPTqnKcmsL9pOEs3jgv9/2ICrxFTrmRY5JIbKxYxZe5X1KhSKMLZvQ/ktvJudT93m6w1+f2Vdb+ARTXVDJ/7PFe+9xTVzZrDffdRffSvKH5xSaMsozGn/hjY1d/eurgIEbj66YWMn77c+t5N3ovWx39n6P/BwH7AE6Hvz8ZJxYxKRKbgDOTuIyKrcKp7jgOeEZHfAiuBoQm1OoZsrJOSTeIdOL+xYhFPvL+y7vsa1brvbyvv5jnrNfKqY+ii/2PkO4/zcpd+3Hr8xcy99DeUAxQWeralvEeZjfcY4yJadc63AUTkVlX9ecSPXhKR2bFeWFXP9vjR8fE1MX6WYRGcRALplLlfeW6/rbyb55hMm+1baL+hkoX7d+GZbieyoqQd73XsTlkcd25WQ8aYxvxk9ZSKyEGq+jmAiHQCUj/nPcUswyIYiQRSt/r5kdsbjb2octqSWdw04yGqC4v4+YgHqS4s4r2O3evdufk5Cdl4jzGN+Qn8VwOzROTz0PcdgRGBtchkNK+AWblpG33HzXC9wyr0WDGrUJyqO5FjMh02rua26ffzsy8XsviArnw7/n/Zd4V7CWevk9ANz39cd7fnd7UuY/KJnzV3XxeRzkDX0KZlqloVbLNMpvIaOBeo2x555Q3QvJmwrbpx8D2794HArjGZdl9/yWuPXsGOwmbcetKldLv1j5T3bM8cj7Z4nYS2VdfWtcXval3G5JOYgV9EWgDXAB1U9WIR6SwiXSIWYTd5xG3gXGic/rWtuoZbXlrM9uraRhOxCgR+elAbZi5bS6dRr3B44TaG9OrCzKVF3N3vHN475mQuHNo3Zled10nITaEItapZP95jM9JNKvjp6nkUmA/8NPT9KuBZwAJ/Bgo6MLgNnHsFX69Ca612L+LDld9RtPk7bp/1KOVLZnHq8H8w8rcnUn7DY77bMnJgF656eqGvx9aq8sW44Kpzukn1Z2EZSiZV/EzgOlhV7wCqAVR1G9QriW4yRGQt+nAN+xueX5Ty4mSRxbhGDuwS9y/Dpq07OPGjt3jrwUs48+M3ebzHICqbt+SqpxfSd9wM3+0t71HGXi2KfD02Wp9+xYJK+o6bQadRr8S1/2iC+CxsRrpJFT+Bf4eIFBO6mxeRgwHr429ifoJTOgLD+OnLXWf5Cc4M2oYKa2uY9Oxo/vbSnVS23pdTLribsf0vqpt5G2+AHH3KjxvN0m0oWp9+UCfLID4Ly1AyqeIn8I8GXgcOFJHJOOWUrw+0VaYev8EpHYHB67UVGHPqrqAs6vTzN9+tOZ/vfzA3nXgJg88bz9J9D2r03HgCpFup6PP6tPddOjqok2UQn4WtcmVSJWofv4gUAHvhzN7tg3Mh9wdVXdcEbTMhfnPn01GqwmufZSXFdW2bPvE5/jB1AnedcS0nDx8Mgyfw3POLqG1wTJFWb9rmu488mTkbQZ0sg/gsbEa6SZWogV9Va0XkclV9BnilidpkGvATnCoWVPJD1c5Gj/ETGJIZhIwajDZsoPz+MZQ/9BC0b88Dw7pBxOtGllZuqKRFUZMMZAZ1sgwiSNuMdJMqfrJ63hSR63CWTPwhvFFVNwTWKlNPrODUMNsjbK8WTu36aIEhnkyRaCeIRts/mwMnXQHr18N118GYMbDHHnWvFb5Kd2t7cVEhqjRJqYWgrqKDCtLJ3N1YKqgJ8xP4Lwr9f1nENgUad86apLn9ccYKTm5dQQAtmjeL+Ycdq4873JaSFkVs2b6T6lpnKLfhCaLRft5cAR07wvTp0L275/69AuTVHmmaqR6vCPIqOpPKhlgqqIkk6rV6dQbp2bOnzps3L93NCJzX1e/YwU75Yq/g1GnUK56ZNbFy172eG9632wklUllJMXNGHQc7dsCdd0KXLjBkCOzcCSJQGD3jxkvfcTM8xw7mjDouodfMZ/Z+5icRma+qPRtu9zNzd3fgUqAfzpX+O8A/VHV7yluZQtl4Wxvt6jva4tXx9FM3fF9aFxexaVvjiVZC464WN5WbtsG778KIEbBkCVP7nMp1H+ye9HtuA5mpZamgJpKfrp5/ApuBe0Lfnw08TkC19FMhyNvaIE8osQqgee3LLUgWFQobfqii4yhnTH6vFkUMOqIdU+dX1ntfigqFAiCyqELD77203raZUbMehb+8werW+zJm6GjeOKhX3WvH+543fG+HHFXGzGVrs+rknalscSITKWZXj4h8pKo/ibUtSPF29QR1WxutKyYVA25elST97CvydUpaFPHd1mpfwTsZv1z2LvdMu4OHe5Vzd99z6i1/GObnPa9YUMktLy12LfFQUlzEmFOjD1Cb2IL43TWZL+GuHmCBiPRR1fdDL9QbPAsmZoSgbmtTvahHwz/GaEE/1r4iBxL7jpvhWScnWe03ruHH3/yX17r247UufTn+4n/w5V77ez4+1nvulZEUtmlbtQ1CpkCqBrGzsQvVNOYn8PcGfiMi4bXz2gNLRWQRoKp6RGCtS1BQt7WpPqF4ZeN41a/3u68g+m2LaqoZ/u8XuOK9p/h+tz2YccjRVDVrHjXoQ+xxhlh3OWArZqVKsllGlhmUO/wE/pMCb0WKBTUwmOoTileArlWlLMq+Yl11xVOu2I+eqxYzdvp9dF63klcPPYYxJ4ygqlnzmM9ze8/jvcsJs0HI9LNlLHOHn4VYvmyKhqRSULnZXieU/l1LPVefiibaicRrXx33LubqpxfWpWA2vOqqWFDJ1h2NZ/Am6oDvvuHpJ2/g65Z7c9GQm5lxyNFRH79H80K27qjxfB+87nJisUHI9LPMoNzh54o/KwUxecbthNK/a2mjTBm/t7/R7ky89jX5/ZWui56EJ1x59ZeHyxe79f3v1aKI77ft3HX1rcoRX3/Gx+0OZVXrtlx62ihmdzrSdfC2oVqFc/u0Z+aytVz99ELGT19e73gSCRKWxpkZLDMod+TsBK6mGoSKN4OoYbv6dy31nbLotS9w8u6jFUybM+o4bqxY1OjEUVxUyJCjynjifWcIp/3GNdz2xv30W7GQUy64m8VtD479Jri0peE+wtkjXscQuUJWPO+JaTqWGZR9ksnqyTpNmcfvFYjdrmzd2jV1fqXvP5xoV8v7lxRHvRWvWFDJ1PmV9QKyAEe2b83U+ZUU1VRz8b9f4Mr3nqK6oJDRJ45gaWnHmG1y43VHUt6jzPMuJ3J28uT3V7J/STEThnW3gJJBrEhc7sjJwB/UIJRb4HZbbxbcb3+TbVe0hc5HDuziWe1y/5Ji130r8P7nG6mtreGFydfTfc1ndYO337bcO2Z74hE+KXkFD8AyRrJAJtUfMonLycDflHn8invXhluftN/yyl5XVG59/ILTpx5+jFsf/4YfqhoteA6wZ9VWtjQvBilgyk9O4m/HnB1z8DYWPydCt+DRd9yMlJ2sLdfcmOj8rMCVdYJaqSjaalN+VnyK1a5oK215ddWc26c9t5U73STlPcoYclRZozVwGwV9VU5d8jYzHxjOr5a/C8DTPxkYM+jv1qzAdX3d4iLn16hQpO5E2NAPVTujLmeYqpN1U607bEw2y8kr/v5dS+sGKxtuT0aswdNYEimvHJmx43a38crHa+oNhG7dsdOz2ibsGrz9+YoFfNTuUD5v4/9KuGpnLXcP6x6zm8Zt/7Fm4CaaMdLw6v6Hqp2Wa25MDDkZ+GcuWxvXdr+SnRgWa3AskavejVur61I0Y03aOm/Bq9w44yGqCwq565QrmHzkL1m/Pb6KPn67adxEBmC37KbItFiI/d66jbl4sVxzY3bJycAfVB9/KrIaog2OeV31+ilr4MfG3Vsy46CeTBx8JS+OHcY9o+JbTbOkuMi1/zye97Vy0zY6jnql3lhAOLsp3mqc8UwGs1xzY3ZJSx+/iKwQkUUislBEUr7CSlB9/EEPGo4c2IXiosYLlyQa9Ftt38L/vH4vw+dOBeCVw37GtWfexIVn9gPiez+KCoRf/aSda/95SWhyWDzcUj5nLlvLnFHH8cW4QXVZSp1GvULfcTNc++j9nnCEXaWtra/fmPRe8fdX1XVBvHAQtXr8zg1I5uTQ8I5CxJkJG6+S3Ztx2rJ3uOKl+yjZ/j2P9DurboJXrCwhN2Wh53mNQYQHfZO9JwkHcr/vtdcd0l4timjRvFmjdNvw68z7coNNEDN5LS0zd0VkBdDTb+DPhJm7fmbopnpmY8c4u2IAOm/5lifmT6Lt+29Dr14wcSL06NHocbHKIYdFHl+09vQ9uA1z/ruh0fbiogK2V9f6OimE9+V3NnSs99vrdaLNLDYml3jN3E1XOqcCb4jIfBEZ7vYAERkuIvNEZN7atckNyqaCn3GDWFk5flQsqKTvuBl08hn0WxQVUFK8q6ulXdX3tPlkAdxzD/zrX65B36utDTW8SyoUt0RNZ/uK9e7vz46dGvW5bvvyO0ZT3qOMsYO7eabSRku/jRTvZ2RMtktXV09fVV0tIvsCb4rIMlWdHfkAVX0AeACcK/54XjyIkg0lLYpcC5xF9pMnO6js9yo80tbqWrp/tYQjVnzCP/qcwey9D6HP7x/lpr69KY+y0Hm0Nrl1C4H3WEONqufrhZ/j9tzwlXdZg33Fk9qZyGC5G8v6MfkkLVf8qro69P+3wAtActNFG0jFlXekigWVbNneuNRxUaHUuyJOdlA53pLFrbZv4X+m38uTk67j3IWv0WKHE7zWF+wW81i92lQowoRh3V0Xdy/zeE5ZSbHvYywUqbs6nzCsOyvGDWq0L7dB7kTGaNxex+u+w7J+TD5p8it+EdkDKFDVzaGvBwB/TuU+glgpq9pllHWP5s0aBaxkBpV9t0+VU5e+zc1vPUTJtu95oNfp3N3vHLY297778JM3D86VudfdUazj83O3UqvKF+MGRX1MqoqB+Smj3fAYjMkHTT64KyIH4Vzlg3PieVJVb4/2nHQvtt5p1Cueg5NloaqYkbNY4wlY8S5DKEDp5vXMfnA4y0s7cMOAy1nS9iDXdsUadB5yVBlT5n7luk+/ZaUjj8/PsUSWX05XNo3V8jH5wmtwNyfr8SeSXRMtGESrgx8p3uwQP336hQVCy92a8cOWbZzz1Qf0uP4Syo88gJlTpvPbBVXUFrj34/c9uA2TL/5p1PaHT1puvwECMa/Mo/FzbJZNY0ywMi2rJ1Cxsj0ailXYa+TALp59w5HiHUfw06dfAPyt/VY+e+3/ccvTt1O+dQUAN35Z5Bn0Aeb8dwM3VjhdNtG6vrz6tlsXF9VlFyUy8anhZ+CW1WPZNMakR04GfnACT3gWqNtAZaRYg8HlPcp8T06KZxwh1mNbbd/CLa/ew88vOh02b4Zp06BfP9/7mTL3KyD6oLPbAGhRgfDDjp1JV7iM/AxqPe4sLZvGmKaXs4E/Hn4Gg70yWhqKJzsk6mNVmTLlT5z58Rs82Ot0WLwYTjklrv2E+9i9slv6dy2tuzKPnAtQo0p1Tf1AnezVeVBlNIwx8bPAj7+g5FVHJ1K82SH9u5Y26kI6YNPXNKvZCSKMPfZCTjt/Ao8Nvhz23LPe4/y0J9y94lanX4Gp8yvrruJ/2LErXdWrTEQyV+epStE0xiTPAj/+gpLbuMF5fdr7HkdoqOHCKs1qdvL795/l/x6+lAvnTQPg3U49+PyAQ12DY2R7vJzd+8C6r2cuW+s5Y/WWlxY3usJ3k8zVebzjLsaY4ORkWeZ4+c0bT+V6o5HjCketWsL/TL+XLutW8n+H9eXffQYg6j571qs9N1YsqkvNLBTh7N4H1q3MBdG7s/yMX6Ti6tzWazUmM1jgD/ETlFKR/x1+jXB65e/ff5Y/vj2Jypal/HbITcw4pDdfjB1U97irn17I+OnLY+6rZ4c2dRUn92u9Oz07tKn382hlEKKlqnqVbzDGZC8L/D6lov5P3Wvs2ElR7U6qC4uYe+DhPNirnAn9zmVr82LKSorj3pefx0ebdTtm2mI2bWtch6ikuIiFowf4OjZjTPawwO8h1Wu5Viyo5NpnPqJsw2pue+N+vtyrHTcNuJQPyw7jw7LDgF2BOFp6qdu+/Dw+VnfWyGc/qleWoqhAGHPqj2MelzEm+1jgd5HqtVwrFlRy87MfMuK957jyvaeoLijkzc696z0mskLl1U8vjGtf8ZQxdjtxpKo2jjEmO1jgd5HqtVyff+xVnnnydrqu+5JXDz2GW04Yzjct96n7ecO6OPGUJU7k8W5s4NWY/GHpnC785qv7zXT5oqqAZrU1/HbITVx6+p/qBX231/DK0f+haqfr7FnLkTfGxMOu+F3EWss1ZneIKjz1FLzxBjzyCLUdO3Hi7+5Hpf55tlDENZc9/P0tLy2ut/jLpm3VroO81lVjjIlHTlbnhORSL5NaO/fzz+HSS2H6dOjZE958k4ovfkjo9VJdXtoYk1+8qnPm5BW/2+Ds1U8vZN6XG+omNUU7MSR0BV1dDX/9K9xyCxQVwd/+5pwACgsp71ES/+uR+gVljDEGcvSK3+tKWYAJw7oDjVeLSro2/KZNcNhhcMwx8L//CwcckNjrRIi2DkDDdWqNMaahvKrH73VFrDhX3Slbk3fjRucKv7oaSkpg4UKYOjUlQR+iF2JLtFSyMcbkZOCPlsa4etO25LtQVGHKFOcK/9Zb4Z13nO1t28bb1KhiFWKzhUyMMYnIyT7+kQO7cPXTC12Lj4VPCtHy3t36/8G5W2j2xefcMXMivT+bB716wWuvQY8egR1LOL/ea93fTOrvt7VsjckOORn4y3uU8ey8lcz574Z62yNz273q1rgNDI987iNQqK6p5YWX7uSQ9SsZc8IIai65hFt7dG+SY0rFJK0gpaKWkTGmaeRk4K9YUMmHK7+rt02AIUfVn53qdnXad9yMRv3/3VYu4T97H0j17nvyx19ewfe77cnXrfZBPqjkqINKmySwRSuylgnirS9kjEmfnAz8bkFIcRYjCWtYoqBiQWWjLJpW27fwx7cf49yFr3N/nzO44xcX8Glpx3qv+afnP26SwJbsJK2gu2Es9dSY7JGTgT/eINRowpYqpy6dzU0zHqTN1u95qOdp3PvTYa7P3Vpdy40Vi+otehKUROvpNEU3TKZ3RRljdsnJrJ7WEQuH+9ne8A7hqjlP8reXxrO6ZSmnnj+BvwwYztbm3gFsytyvkmtwwFKWvhqF1QsyJnvk5BW/NFzBPMb21Zu20axmJy2rfmBji9Y8d/jxbCxuxeM9TqZdmz0ZP7AL877cwBPvr3R9fk2GT4Jrim4YqxdkTPbIycC/KaKwmZ/tA777nKuf+ytrWu3DhWeMYVXJfkw66pR6NXHKe5Qxee5K3GJ8odcZJUM0VTeMlXY2JjvkZFdPtLr19WzcCJdcwsR/XEmrHVuZ3P3kutsCt26Kc3u3d33ds3sfmHyjA2TdMMaYSDkZ+H0Fun//25l5++CDcM01zH/1XZb2OhbBqYPjVrfntvJunNenfd0VfqEI5/Vp3yQDu8mInAEc7fiMMfkhJ4u0QZT0xdpaKChwiqqdd55TciHAmbfGGJMuGVWkTUROEpHlIvIfERkVxD7mfbmBr7/bjgJff7edD//7DYwb51TPDBdVe/llKtiXvuNm0GnUK/QdN8OKnhljcl6TD+6KSCFwH3AisAr4QESmqeqSVO3jxopF9TJwfrJqCec8dCms+xIGD4YtW2CvvazMgDEmL6Xjiv9o4D+q+rmq7gCeAk5L5Q7CefXFO7Zz2/T7eP6JkbSs2srwITc5ZZP32gtomvx2Y4zJNOlI5ywDImc8rQJ6p3IH4bz66sJmdF/zKQ/2KmdCv3MbTcKyMgPGmHyUjsDvlvTeaIRZRIYDwwHat3dPo4xlZ2EzTv/1nVQXus/YtTIDxph8lI6unlVAZOL7AcDqhg9S1QdUtaeq9iwtLU14Z15BHyy/3RiTn9IR+D8AOotIJxFpDpwFTEvlDko8avIUF9U/XMtvN8bkoybv6lHVnSJyOTAdKAQeUdXFqdyHVwWFbdW1VCyorBfYrcyAMSbfpKVWj6q+Crwa1Ot71eQBPBcGsWUDjTH5IidLNsRabL2hcD5/5aZtKLvy+W0ylzEmF+Vk4B85sItr6hC4nxQsn98Yk09yMvCX9yjj3D7tGwV/r4wdy+c3xuSTnAz84FTSnDCsu6+MHd9lnI0xJgfk5EIsYX4zdkYO7FJ/zV0sn98Yk7tyOvD7ZcsGGmPyiQX+EMvnN8bki5zt4zfGGOPOAr8xxuQZC/zGGJNnLPAbY0yescBvjDF5RlQbrYGScURkLfBlgk/fB1iXwuZki3w8bjvm/JGPx53IMXdQ1UYLmmRF4E+GiMxT1Z7pbkdTy8fjtmPOH/l43Kk8ZuvqMcaYPGOB3xhj8kw+BP4H0t2ANMnH47Zjzh/5eNwpO+ac7+M3xhhTXz5c8RtjjIlggd8YY/JMTgd+ETlJRJaLyH9EZFS629MURGSFiCwSkYUiMi/d7QmKiDwiIt+KyCcR29qIyJsi8lno/73S2cZU8zjmMSJSGfq8F4rIyelsY6qJyIEiMlNElorIYhH5Q2h7zn7WUY45ZZ91zvbxi0gh8ClwIrAK+AA4W1WXpLVhARORFUBPVc3pyS0i8nNgC/BPVT08tO0OYIOqjgud6PdS1T+ms52p5HHMY4AtqnpnOtsWFBFpB7RT1Q9FpCUwHygHLiBHP+sox3wmKfqsc/mK/2jgP6r6uaruAJ4CTktzm0yKqOpsYEODzacBk0JfT8L5Y8kZHsec01R1jap+GPp6M7AUKCOHP+sox5wyuRz4y4CvIr5fRYrfvAylwBsiMl9Ehqe7MU2sraquAeePB9g3ze1pKpeLyMehrqCc6fJoSEQ6Aj2AueTJZ93gmCFFn3UuB35x2Zab/Vr19VXVI4FfApeFugdM7vo7cDDQHVgD/DWtrQmIiOwJTAWuUtXv092epuByzCn7rHM58K8CDoz4/gBgdZra0mRUdXXo/2+BF3C6vPLFN6H+0XA/6bdpbk/gVPUbVa1R1VrgQXLw8xaRIpwAOFlVnw9tzunP2u2YU/lZ53Lg/wDoLCKdRKQ5cBYwLc1tCpSI7BEaDEJE9gAGAJ9Ef1ZOmQacH/r6fODFNLalSYSDX8jp5NjnLSICPAwsVdW7In6Us5+11zGn8rPO2awegFC6091AIfCIqt6e3hYFS0QOwrnKB2gGPJmrxywiU4BjcUrVfgOMBiqAZ4D2wEpgqKrmzGCoxzEfi3Prr8AKYES47zsXiEg/4B1gEVAb2vwnnD7vnPysoxzz2aTos87pwG+MMaaxXO7qMcYY48ICvzHG5BkL/MYYk2cs8BtjTJ6xwG+MMXnGAr8xLkKVEK9rsG2FiOyTrjYZkyoW+I0xJs9Y4DdZSUTOE5F/h+qSTxSRQhHpFSpgtXtoFvNiETlcRI4Vkdki8oKILBGRf4hIUr/7IlIRKoS3OLIYnohsEZHbReQjEXlfRNqGtg8VkU9C22eHthWKyHgR+SDU7hGh7ceKyCwReU5ElonI5NBszoZtmCUid4vIe6HXzrlyDSYYFvhN1hGRw4BhOAXpugM1wLmq+gHOVP7bgDuAJ1Q1PK39aOBaoBtOoavBPnZ1dcSiFwuB/SN+dpGqHgX0BK4Ukb1D2/cA3lfVnwCzgYtD228GBoa2nxra9lvgO1XtBfQCLhaRTqGf9QCuAn4EHAT09WjjHqp6DHAp8IiPYzKGZulugDEJOB44CvggdCFczK4iXX/GqdO0Hbgy4jn/VtXPoa70QT/guRj7mRC56EVokZuwK0Xk9NDXBwKdgfXADuDl0Pb5OAsBAcwBHhORZ4BwobEBwBEickbo+9ah19kRau+q0H4XAh2Bd13aOAWcWv0i0kpESlR1U4zjMnnOAr/JRgJMUtUbXH7WBtgTKAJ2B34IbW9YmyThWiUicixwAvBTVd0qIrNC+wKo1l11UGoI/Y2p6iUi0hsYBCwUke6h47hCVae7vH5VxKa613GRsuMy+cO6ekw2egs4Q0T2hbr1VzuEfvYAcBMwGfhLxHOODlVqLcDpJnK7evarNbAxFPS7An1iPUFEDlbVuap6M7AO5y5hOvD7UAleROTQUFXVeAwLPbcfTrfRd3E+3+Qhu+I3WUdVl4jIjTgrjRUA1TiLzvwC2KmqT4qz5vJ7InIcToXDfwHjcPr4ZxOqYioiDwH/UNV4FqZ/HbhERD4GlgPv+3jOeBHpjHOV/xbwEfAxThfOh6HB27XEv4TgRhF5D2gFXBTnc02esuqcJueFuk6uU9VfpbkpKRXqYrouzpOWMdbVY4wx+cau+I0xJs/YFb8xxuQZC/zGGJNnLPAbY0yescBvjDF5xgK/Mcbkmf8PYek33X1CU94AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot exp vs pred in test set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "ln = np.arange(0, 25, 0.2)\n",
    "plt.plot(ln, ln,'r--')\n",
    "plt.scatter(test_results[1], test_results[0])\n",
    "plt.xlabel('exp. Hansen p')\n",
    "plt.ylabel('pred. Hansen p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred_test=pd.DataFrame(test_results[0], columns=[\"predict\"])\n",
    "pd_exp_test=pd.DataFrame(test_results[1], columns=[\"exp\"])\n",
    "pd_smiles=pd.DataFrame(dataset['test']['smiles'], columns=[\"smiles\"])\n",
    "pd_test=pd.concat((pd_smiles, pd_exp_test, pd_pred_test), axis=1)\n",
    "\n",
    "# save predicton to csv \n",
    "pd_test.to_csv('hansen_p_bert_ds6_fold1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5108c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04564f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f50f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
