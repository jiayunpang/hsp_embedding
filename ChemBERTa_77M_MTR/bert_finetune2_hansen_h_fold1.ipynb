{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0df1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c986d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-330d8a5435e88b37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/pj11/.cache/huggingface/datasets/csv/default-330d8a5435e88b37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98d3cea8d0e4f1f8ce958fca27c9055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551f6c54e21d44e998654aa38f032f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/pj11/.cache/huggingface/datasets/csv/default-330d8a5435e88b37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb25560fc64d58b279f63b1cb29df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the code is adapted from the \"fine-tuning a pretrained model\" and\n",
    "# \"fine-tuning a model with the trainer API\" course and examples on hugging face\n",
    "# check huggingface for further explanations\n",
    "\n",
    "# load data into training, valdidation and test\n",
    "dataset = load_dataset('csv', data_files={'train':['hansen_h_bert_ds1.csv', 'hansen_h_bert_ds2.csv',\n",
    "                                                   'hansen_h_bert_ds3.csv', 'hansen_h_bert_ds4.csv'],\n",
    "                                          'validation':'hansen_h_bert_ds5.csv',\n",
    "                                          'test': 'hansen_h_bert_ds6.csv'}, delimiter=',', column_names =['smiles', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9874b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': 'CC\\\\C(C)=N\\\\O', 'label': 7.8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data format\n",
    "dataset['validation'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9894c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# specify model from hugging face\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepchem/ChemBERTa-77M-MTR\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b48772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edaf1e8df96487382fb75d6c23d51ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9718ad7e0a0e4cd28ef7c078703ffe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bcc6bde1bd43e290cb2ca1bab1b5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009f538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 789\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f040040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=random_state).select(range(1000))\n",
    "#small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=random_state).select(range(1000))\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]\n",
    "small_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b5f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepchem/ChemBERTa-77M-MTR were not used when initializing RobertaForSequenceClassification: ['norm_std', 'norm_mean', 'regression.out_proj.weight', 'regression.dense.weight', 'regression.dense.bias', 'regression.out_proj.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at deepchem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# for regression, num_labels=1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"deepchem/ChemBERTa-77M-MTR\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663b29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90cab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metric\n",
    "mae_metric = evaluate.load(\"mae\")\n",
    "mse_metric = evaluate.load(\"mse\")\n",
    "pearsonr_metric = evaluate.load(\"pearsonr\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update({'mae': mae_metric.compute(predictions=predictions, references=labels)})\n",
    "    metrics.update({'rmse': mse_metric.compute(predictions=predictions, references=labels, squared=False)})\n",
    "    metrics.update({'pearsonr': pearsonr_metric.compute(predictions=predictions, references=labels)})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574f2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the finetuned model\n",
    "para_output_dir = 'C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/'\n",
    "model_output_path = f'{para_output_dir}/model'\n",
    "\n",
    "# specify trainining arguments \n",
    "training_args = TrainingArguments(output_dir=para_output_dir, \n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size = 4,\n",
    "                                  per_device_eval_batch_size = 4,\n",
    "                                  num_train_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794a8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 789\n",
      "  Num Epochs = 150\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7500\n",
      "  Number of trainable parameters = 3427825\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 14:11, Epoch 150/150]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Pearsonr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>50.139820</td>\n",
       "      <td>{'mae': 5.21137655779795}</td>\n",
       "      <td>{'mse': 7.060844249898687}</td>\n",
       "      <td>{'pearsonr': 0.02788466507689704}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>27.573797</td>\n",
       "      <td>{'mae': 3.9884939133213257}</td>\n",
       "      <td>{'mse': 5.2339239332578265}</td>\n",
       "      <td>{'pearsonr': 0.11190824025586785}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>26.901411</td>\n",
       "      <td>{'mae': 3.9112087034331964}</td>\n",
       "      <td>{'mse': 5.1700296751603165}</td>\n",
       "      <td>{'pearsonr': 0.21838309677461376}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>23.474947</td>\n",
       "      <td>{'mae': 3.3849094119773904}</td>\n",
       "      <td>{'mse': 4.830846667027899}</td>\n",
       "      <td>{'pearsonr': 0.5433936335849421}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>20.549311</td>\n",
       "      <td>{'mae': 3.1502253301252567}</td>\n",
       "      <td>{'mse': 4.518617861990051}</td>\n",
       "      <td>{'pearsonr': 0.6374618170154429}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>17.344416</td>\n",
       "      <td>{'mae': 2.802415465037835}</td>\n",
       "      <td>{'mse': 4.150830885893228}</td>\n",
       "      <td>{'pearsonr': 0.6753667485422742}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>17.300608</td>\n",
       "      <td>{'mae': 2.947253050868811}</td>\n",
       "      <td>{'mse': 4.147662600714179}</td>\n",
       "      <td>{'pearsonr': 0.7454932606980748}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>14.413368</td>\n",
       "      <td>{'mae': 2.483743477442543}</td>\n",
       "      <td>{'mse': 3.7852432686841713}</td>\n",
       "      <td>{'pearsonr': 0.7394796855086048}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>14.594078</td>\n",
       "      <td>{'mae': 2.638696959081489}</td>\n",
       "      <td>{'mse': 3.8105777951870428}</td>\n",
       "      <td>{'pearsonr': 0.7746355670272569}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>13.219987</td>\n",
       "      <td>{'mae': 2.4284820299463226}</td>\n",
       "      <td>{'mse': 3.627668793818194}</td>\n",
       "      <td>{'pearsonr': 0.7812448199851219}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>11.906830</td>\n",
       "      <td>{'mae': 2.2506682105778437}</td>\n",
       "      <td>{'mse': 3.4433812024019135}</td>\n",
       "      <td>{'pearsonr': 0.7745585188105992}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>11.770116</td>\n",
       "      <td>{'mae': 2.2716012129626297}</td>\n",
       "      <td>{'mse': 3.425348551378091}</td>\n",
       "      <td>{'pearsonr': 0.7931682982033528}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>11.282457</td>\n",
       "      <td>{'mae': 2.1864568676591523}</td>\n",
       "      <td>{'mse': 3.3545139454576836}</td>\n",
       "      <td>{'pearsonr': 0.7960455967955973}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>11.161923</td>\n",
       "      <td>{'mae': 2.1923460727983017}</td>\n",
       "      <td>{'mse': 3.3387039892163988}</td>\n",
       "      <td>{'pearsonr': 0.8008132067252085}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>10.594953</td>\n",
       "      <td>{'mae': 2.108789197760185}</td>\n",
       "      <td>{'mse': 3.2534748748178166}</td>\n",
       "      <td>{'pearsonr': 0.7984036226951619}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>10.239701</td>\n",
       "      <td>{'mae': 2.083266398628351}</td>\n",
       "      <td>{'mse': 3.199850020992348}</td>\n",
       "      <td>{'pearsonr': 0.8078063650177758}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>9.933168</td>\n",
       "      <td>{'mae': 2.0594068095088005}</td>\n",
       "      <td>{'mse': 3.1524329238527735}</td>\n",
       "      <td>{'pearsonr': 0.8034143409153466}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>10.821884</td>\n",
       "      <td>{'mae': 2.2576751213539676}</td>\n",
       "      <td>{'mse': 3.2924741230494305}</td>\n",
       "      <td>{'pearsonr': 0.8126077302417902}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>25.303800</td>\n",
       "      <td>10.196537</td>\n",
       "      <td>{'mae': 2.1456710664451424}</td>\n",
       "      <td>{'mse': 3.1980162574867026}</td>\n",
       "      <td>{'pearsonr': 0.8125597996066156}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.979133</td>\n",
       "      <td>{'mae': 2.134973634696249}</td>\n",
       "      <td>{'mse': 3.164878556710466}</td>\n",
       "      <td>{'pearsonr': 0.8128496281691338}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.699570</td>\n",
       "      <td>{'mae': 2.0497331128167318}</td>\n",
       "      <td>{'mse': 3.124163958854226}</td>\n",
       "      <td>{'pearsonr': 0.8153307086821947}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>10.058547</td>\n",
       "      <td>{'mae': 2.20578007615611}</td>\n",
       "      <td>{'mse': 3.180203653579391}</td>\n",
       "      <td>{'pearsonr': 0.8154859812031692}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.209309</td>\n",
       "      <td>{'mae': 2.0311871406239304}</td>\n",
       "      <td>{'mse': 3.043876987511429}</td>\n",
       "      <td>{'pearsonr': 0.8185837562093854}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.352084</td>\n",
       "      <td>{'mae': 2.084999026305179}</td>\n",
       "      <td>{'mse': 3.0672691622398554}</td>\n",
       "      <td>{'pearsonr': 0.8206767203576485}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.913900</td>\n",
       "      <td>{'mae': 2.198586811193355}</td>\n",
       "      <td>{'mse': 3.1590917224807593}</td>\n",
       "      <td>{'pearsonr': 0.8215093156816442}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.722620</td>\n",
       "      <td>{'mae': 2.160260354655648}</td>\n",
       "      <td>{'mse': 3.128847664899771}</td>\n",
       "      <td>{'pearsonr': 0.8247624801223645}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.659702</td>\n",
       "      <td>{'mae': 2.1519910373209696}</td>\n",
       "      <td>{'mse': 3.119455894553761}</td>\n",
       "      <td>{'pearsonr': 0.8248809489150328}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.296594</td>\n",
       "      <td>{'mae': 2.071230164298854}</td>\n",
       "      <td>{'mse': 3.0615679193145184}</td>\n",
       "      <td>{'pearsonr': 0.8229361170433278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>9.931300</td>\n",
       "      <td>9.427642</td>\n",
       "      <td>{'mae': 2.1166278972541015}</td>\n",
       "      <td>{'mse': 3.0846479341171364}</td>\n",
       "      <td>{'pearsonr': 0.8236799859690787}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.727118</td>\n",
       "      <td>{'mae': 2.1891864902023133}</td>\n",
       "      <td>{'mse': 3.133641944982606}</td>\n",
       "      <td>{'pearsonr': 0.8215151345147852}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>8.890274</td>\n",
       "      <td>{'mae': 2.0152995685862405}</td>\n",
       "      <td>{'mse': 2.9970989329095565}</td>\n",
       "      <td>{'pearsonr': 0.8258802798956335}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.405559</td>\n",
       "      <td>{'mae': 2.1563163057045283}</td>\n",
       "      <td>{'mse': 3.081515493293431}</td>\n",
       "      <td>{'pearsonr': 0.8245486951716019}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.547001</td>\n",
       "      <td>{'mae': 2.1648512423076305}</td>\n",
       "      <td>{'mse': 3.1058768140401867}</td>\n",
       "      <td>{'pearsonr': 0.8293803799427089}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>8.663608</td>\n",
       "      <td>{'mae': 2.004123525211805}</td>\n",
       "      <td>{'mse': 2.958950640699689}</td>\n",
       "      <td>{'pearsonr': 0.8303767720788461}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.107037</td>\n",
       "      <td>{'mae': 2.098997791066085}</td>\n",
       "      <td>{'mse': 3.034028880703916}</td>\n",
       "      <td>{'pearsonr': 0.829895760632964}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.163710</td>\n",
       "      <td>{'mae': 2.1233967555507185}</td>\n",
       "      <td>{'mse': 3.043187214015418}</td>\n",
       "      <td>{'pearsonr': 0.826041447618225}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.259150</td>\n",
       "      <td>{'mae': 2.1320204870198585}</td>\n",
       "      <td>{'mse': 3.0589413814399786}</td>\n",
       "      <td>{'pearsonr': 0.8309148859537743}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.651482</td>\n",
       "      <td>{'mae': 2.2080136610166674}</td>\n",
       "      <td>{'mse': 3.1218829925412863}</td>\n",
       "      <td>{'pearsonr': 0.830098459084835}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>7.453300</td>\n",
       "      <td>9.071863</td>\n",
       "      <td>{'mae': 2.0725387316669908}</td>\n",
       "      <td>{'mse': 3.027382120134418}</td>\n",
       "      <td>{'pearsonr': 0.8303870108348974}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.478221</td>\n",
       "      <td>{'mae': 2.170552216318961}</td>\n",
       "      <td>{'mse': 3.093262365960079}</td>\n",
       "      <td>{'pearsonr': 0.832092639480492}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>8.695113</td>\n",
       "      <td>{'mae': 2.0226010097389295}</td>\n",
       "      <td>{'mse': 2.9621395398473114}</td>\n",
       "      <td>{'pearsonr': 0.8313436530250856}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>8.790036</td>\n",
       "      <td>{'mae': 2.0545199056567274}</td>\n",
       "      <td>{'mse': 2.9787155918376027}</td>\n",
       "      <td>{'pearsonr': 0.8343078729188335}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.326146</td>\n",
       "      <td>{'mae': 2.1547367400702484}</td>\n",
       "      <td>{'mse': 3.067456742889848}</td>\n",
       "      <td>{'pearsonr': 0.8298884384108045}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.087474</td>\n",
       "      <td>{'mae': 2.0693441434162976}</td>\n",
       "      <td>{'mse': 3.0287790479007946}</td>\n",
       "      <td>{'pearsonr': 0.8295647891889997}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.693414</td>\n",
       "      <td>{'mae': 2.2116687511883413}</td>\n",
       "      <td>{'mse': 3.1258849327191367}</td>\n",
       "      <td>{'pearsonr': 0.828977897894833}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.402165</td>\n",
       "      <td>{'mae': 2.144180956376991}</td>\n",
       "      <td>{'mse': 3.0795515768605406}</td>\n",
       "      <td>{'pearsonr': 0.829181068156394}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.173662</td>\n",
       "      <td>{'mae': 2.094326980109445}</td>\n",
       "      <td>{'mse': 3.041661268216163}</td>\n",
       "      <td>{'pearsonr': 0.8291244216076813}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>8.779383</td>\n",
       "      <td>{'mae': 2.041880432421786}</td>\n",
       "      <td>{'mse': 2.975626168938194}</td>\n",
       "      <td>{'pearsonr': 0.8324186694152924}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>5.845900</td>\n",
       "      <td>9.394423</td>\n",
       "      <td>{'mae': 2.1515915070844787}</td>\n",
       "      <td>{'mse': 3.0784801584247705}</td>\n",
       "      <td>{'pearsonr': 0.8319560246794284}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.519275</td>\n",
       "      <td>{'mae': 2.142519532367209}</td>\n",
       "      <td>{'mse': 3.0986595370643717}</td>\n",
       "      <td>{'pearsonr': 0.8319157764367178}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.047946</td>\n",
       "      <td>{'mae': 2.0909381844103336}</td>\n",
       "      <td>{'mse': 3.021769404612502}</td>\n",
       "      <td>{'pearsonr': 0.8323053074614656}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>8.900772</td>\n",
       "      <td>{'mae': 2.055233531834813}</td>\n",
       "      <td>{'mse': 2.9958678782563744}</td>\n",
       "      <td>{'pearsonr': 0.832664493321341}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.063191</td>\n",
       "      <td>{'mae': 2.0948930965916155}</td>\n",
       "      <td>{'mse': 3.023650760305088}</td>\n",
       "      <td>{'pearsonr': 0.8327461079131673}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.312298</td>\n",
       "      <td>{'mae': 2.117206831344493}</td>\n",
       "      <td>{'mse': 3.0660750067120515}</td>\n",
       "      <td>{'pearsonr': 0.8341712220524073}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.171075</td>\n",
       "      <td>{'mae': 2.1120937383795146}</td>\n",
       "      <td>{'mse': 3.041866557469705}</td>\n",
       "      <td>{'pearsonr': 0.8313349466068145}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.971538</td>\n",
       "      <td>{'mae': 2.252419908639743}</td>\n",
       "      <td>{'mse': 3.172089233145482}</td>\n",
       "      <td>{'pearsonr': 0.8332719916004697}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.329270</td>\n",
       "      <td>{'mae': 2.1214170429836674}</td>\n",
       "      <td>{'mse': 3.0678608447103204}</td>\n",
       "      <td>{'pearsonr': 0.8314733932179896}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>9.686541</td>\n",
       "      <td>{'mae': 2.1603940530174275}</td>\n",
       "      <td>{'mse': 3.127510902537873}</td>\n",
       "      <td>{'pearsonr': 0.8327944972876821}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.784800</td>\n",
       "      <td>8.995915</td>\n",
       "      <td>{'mae': 2.0669458904469074}</td>\n",
       "      <td>{'mse': 3.011859668389614}</td>\n",
       "      <td>{'pearsonr': 0.8323820335853669}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.564175</td>\n",
       "      <td>{'mae': 2.138288394061064}</td>\n",
       "      <td>{'mse': 3.1073075264917467}</td>\n",
       "      <td>{'pearsonr': 0.833849952488244}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.214290</td>\n",
       "      <td>{'mae': 2.099921704397589}</td>\n",
       "      <td>{'mse': 3.0474210377202353}</td>\n",
       "      <td>{'pearsonr': 0.8322372316652621}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.268304</td>\n",
       "      <td>{'mae': 2.0677354306663354}</td>\n",
       "      <td>{'mse': 3.0588828712710865}</td>\n",
       "      <td>{'pearsonr': 0.8310500543292968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.317424</td>\n",
       "      <td>{'mae': 2.1254388905948187}</td>\n",
       "      <td>{'mse': 3.065237271969921}</td>\n",
       "      <td>{'pearsonr': 0.8317004397951092}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.077973</td>\n",
       "      <td>{'mae': 2.0622250526235795}</td>\n",
       "      <td>{'mse': 3.02531637041648}</td>\n",
       "      <td>{'pearsonr': 0.8317402500236271}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.516899</td>\n",
       "      <td>{'mae': 2.1286677983660383}</td>\n",
       "      <td>{'mse': 3.097834506960411}</td>\n",
       "      <td>{'pearsonr': 0.8304305096139513}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.595406</td>\n",
       "      <td>{'mae': 2.1355283254105126}</td>\n",
       "      <td>{'mse': 3.111504101925537}</td>\n",
       "      <td>{'pearsonr': 0.8295866723232952}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.100288</td>\n",
       "      <td>{'mae': 2.064348912840416}</td>\n",
       "      <td>{'mse': 3.0296497185583533}</td>\n",
       "      <td>{'pearsonr': 0.829759695261445}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.517399</td>\n",
       "      <td>{'mae': 2.146602800673791}</td>\n",
       "      <td>{'mse': 3.0973141686497176}</td>\n",
       "      <td>{'pearsonr': 0.8294350912894397}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>4.369700</td>\n",
       "      <td>9.500547</td>\n",
       "      <td>{'mae': 2.1719156469922836}</td>\n",
       "      <td>{'mse': 3.0937828265169456}</td>\n",
       "      <td>{'pearsonr': 0.8318939952276938}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.316590</td>\n",
       "      <td>{'mae': 2.112240263766746}</td>\n",
       "      <td>{'mse': 3.065524571477365}</td>\n",
       "      <td>{'pearsonr': 0.8319079016738884}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.209518</td>\n",
       "      <td>{'mae': 2.1334732584466183}</td>\n",
       "      <td>{'mse': 3.045999057760123}</td>\n",
       "      <td>{'pearsonr': 0.8340080882090652}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.080381</td>\n",
       "      <td>{'mae': 2.09518682487725}</td>\n",
       "      <td>{'mse': 3.026911155574445}</td>\n",
       "      <td>{'pearsonr': 0.8330544751950721}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>8.981710</td>\n",
       "      <td>{'mae': 2.0646813399333337}</td>\n",
       "      <td>{'mse': 3.010586620271822}</td>\n",
       "      <td>{'pearsonr': 0.8333030430139721}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.618391</td>\n",
       "      <td>{'mae': 2.20798037814799}</td>\n",
       "      <td>{'mse': 3.1128765711403057}</td>\n",
       "      <td>{'pearsonr': 0.8334106537424515}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.291080</td>\n",
       "      <td>{'mae': 2.120159158946445}</td>\n",
       "      <td>{'mse': 3.0613930524389583}</td>\n",
       "      <td>{'pearsonr': 0.83225360909835}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>8.963413</td>\n",
       "      <td>{'mae': 2.063024958623999}</td>\n",
       "      <td>{'mse': 3.0067730397709935}</td>\n",
       "      <td>{'pearsonr': 0.8323630443227559}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.160311</td>\n",
       "      <td>{'mae': 2.0923627033394756}</td>\n",
       "      <td>{'mse': 3.039307504595954}</td>\n",
       "      <td>{'pearsonr': 0.8306946062503884}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>9.026143</td>\n",
       "      <td>{'mae': 2.078691522822465}</td>\n",
       "      <td>{'mse': 3.017931943471011}</td>\n",
       "      <td>{'pearsonr': 0.8320954922879047}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.856800</td>\n",
       "      <td>8.880739</td>\n",
       "      <td>{'mae': 2.066923225648361}</td>\n",
       "      <td>{'mse': 2.9924143665521408}</td>\n",
       "      <td>{'pearsonr': 0.8350216566235558}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.426703</td>\n",
       "      <td>{'mae': 2.1772138002673684}</td>\n",
       "      <td>{'mse': 3.0825945718229}</td>\n",
       "      <td>{'pearsonr': 0.8348078134197723}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.335903</td>\n",
       "      <td>{'mae': 2.1117683523310924}</td>\n",
       "      <td>{'mse': 3.068149684691824}</td>\n",
       "      <td>{'pearsonr': 0.8303060722039419}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.310480</td>\n",
       "      <td>{'mae': 2.127874607589039}</td>\n",
       "      <td>{'mse': 3.0639383358194783}</td>\n",
       "      <td>{'pearsonr': 0.8315332806148168}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>8.898295</td>\n",
       "      <td>{'mae': 2.044404762537044}</td>\n",
       "      <td>{'mse': 2.9967089885531446}</td>\n",
       "      <td>{'pearsonr': 0.8313329049054042}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.220646</td>\n",
       "      <td>{'mae': 2.1165987950026386}</td>\n",
       "      <td>{'mse': 3.049537510932252}</td>\n",
       "      <td>{'pearsonr': 0.8306759491499297}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.101285</td>\n",
       "      <td>{'mae': 2.07159143947254}</td>\n",
       "      <td>{'mse': 3.029515318317259}</td>\n",
       "      <td>{'pearsonr': 0.8281985783647152}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.536063</td>\n",
       "      <td>{'mae': 2.1460003593208525}</td>\n",
       "      <td>{'mse': 3.101687881902961}</td>\n",
       "      <td>{'pearsonr': 0.8283245331149149}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.257955</td>\n",
       "      <td>{'mae': 2.0655233413075584}</td>\n",
       "      <td>{'mse': 3.057101968686687}</td>\n",
       "      <td>{'pearsonr': 0.8256645311325987}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>10.040183</td>\n",
       "      <td>{'mae': 2.2295917322963175}</td>\n",
       "      <td>{'mse': 3.182227703286804}</td>\n",
       "      <td>{'pearsonr': 0.8282453157916965}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.323300</td>\n",
       "      <td>9.167680</td>\n",
       "      <td>{'mae': 2.0723506641493836}</td>\n",
       "      <td>{'mse': 3.0421729897428262}</td>\n",
       "      <td>{'pearsonr': 0.828507218894265}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.298407</td>\n",
       "      <td>{'mae': 2.0874703568666417}</td>\n",
       "      <td>{'mse': 3.063517047554581}</td>\n",
       "      <td>{'pearsonr': 0.8277503871203782}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.577934</td>\n",
       "      <td>{'mae': 2.1357172141749845}</td>\n",
       "      <td>{'mse': 3.109522618796454}</td>\n",
       "      <td>{'pearsonr': 0.827568699921842}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.156198</td>\n",
       "      <td>{'mae': 2.0565502300934138}</td>\n",
       "      <td>{'mse': 3.0410702689882747}</td>\n",
       "      <td>{'pearsonr': 0.8287385173745305}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.021761</td>\n",
       "      <td>{'mae': 2.054764824356827}</td>\n",
       "      <td>{'mse': 3.0180851195006575}</td>\n",
       "      <td>{'pearsonr': 0.830070863425272}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.491572</td>\n",
       "      <td>{'mae': 2.132426251983506}</td>\n",
       "      <td>{'mse': 3.0955534737586095}</td>\n",
       "      <td>{'pearsonr': 0.8280928903211628}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.391665</td>\n",
       "      <td>{'mae': 2.1051929349145913}</td>\n",
       "      <td>{'mse': 3.0789511395343694}</td>\n",
       "      <td>{'pearsonr': 0.8286581520170487}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.514902</td>\n",
       "      <td>{'mae': 2.1440564699395357}</td>\n",
       "      <td>{'mse': 3.0979621913125963}</td>\n",
       "      <td>{'pearsonr': 0.828190836180951}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.395336</td>\n",
       "      <td>{'mae': 2.137357697004292}</td>\n",
       "      <td>{'mse': 3.079008856527507}</td>\n",
       "      <td>{'pearsonr': 0.8282470150195551}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.464151</td>\n",
       "      <td>{'mae': 2.1246826790159727}</td>\n",
       "      <td>{'mse': 3.0906567710415698}</td>\n",
       "      <td>{'pearsonr': 0.8258978676424509}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.126900</td>\n",
       "      <td>9.346173</td>\n",
       "      <td>{'mae': 2.0874935530012633}</td>\n",
       "      <td>{'mse': 3.071352498716619}</td>\n",
       "      <td>{'pearsonr': 0.8266176617270958}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.498480</td>\n",
       "      <td>{'mae': 2.1373693212148197}</td>\n",
       "      <td>{'mse': 3.0951254238822177}</td>\n",
       "      <td>{'pearsonr': 0.8249636812466757}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.665123</td>\n",
       "      <td>{'mae': 2.145829333635378}</td>\n",
       "      <td>{'mse': 3.1230234048343446}</td>\n",
       "      <td>{'pearsonr': 0.8259972569839302}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.697550</td>\n",
       "      <td>{'mae': 2.1691698119951988}</td>\n",
       "      <td>{'mse': 3.128238953058074}</td>\n",
       "      <td>{'pearsonr': 0.8273348591695914}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.551464</td>\n",
       "      <td>{'mae': 2.1451631470153174}</td>\n",
       "      <td>{'mse': 3.1042372616096117}</td>\n",
       "      <td>{'pearsonr': 0.8254502118078066}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.341631</td>\n",
       "      <td>{'mae': 2.1322369654166518}</td>\n",
       "      <td>{'mse': 3.069082907570449}</td>\n",
       "      <td>{'pearsonr': 0.8271110619646551}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.215471</td>\n",
       "      <td>{'mae': 2.1082745105557636}</td>\n",
       "      <td>{'mse': 3.0483736029815285}</td>\n",
       "      <td>{'pearsonr': 0.8272719180348216}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.505445</td>\n",
       "      <td>{'mae': 2.1348818991011775}</td>\n",
       "      <td>{'mse': 3.096559240364433}</td>\n",
       "      <td>{'pearsonr': 0.8288300549176484}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.348381</td>\n",
       "      <td>{'mae': 2.1284308083317605}</td>\n",
       "      <td>{'mse': 3.070132151630674}</td>\n",
       "      <td>{'pearsonr': 0.8299937689466065}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.419054</td>\n",
       "      <td>{'mae': 2.1573451338383145}</td>\n",
       "      <td>{'mse': 3.081097276402115}</td>\n",
       "      <td>{'pearsonr': 0.8299649875159414}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2.852700</td>\n",
       "      <td>9.301092</td>\n",
       "      <td>{'mae': 2.1246319392384008}</td>\n",
       "      <td>{'mse': 3.0624066329911583}</td>\n",
       "      <td>{'pearsonr': 0.8289390186330877}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.148419</td>\n",
       "      <td>{'mae': 2.0981235169630668}</td>\n",
       "      <td>{'mse': 3.0375761547103077}</td>\n",
       "      <td>{'pearsonr': 0.8293027765754359}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.138267</td>\n",
       "      <td>{'mae': 2.099811439756966}</td>\n",
       "      <td>{'mse': 3.035560932588076}</td>\n",
       "      <td>{'pearsonr': 0.8290123028998753}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.183567</td>\n",
       "      <td>{'mae': 2.093029718864993}</td>\n",
       "      <td>{'mse': 3.0429504427516245}</td>\n",
       "      <td>{'pearsonr': 0.8276143147524069}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.566215</td>\n",
       "      <td>{'mae': 2.1779759311528526}</td>\n",
       "      <td>{'mse': 3.105071064830919}</td>\n",
       "      <td>{'pearsonr': 0.8272469569238701}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.249012</td>\n",
       "      <td>{'mae': 2.1197748832915186}</td>\n",
       "      <td>{'mse': 3.053811899404119}</td>\n",
       "      <td>{'pearsonr': 0.8298710229663375}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.432089</td>\n",
       "      <td>{'mae': 2.1364607991376503}</td>\n",
       "      <td>{'mse': 3.0844672624776783}</td>\n",
       "      <td>{'pearsonr': 0.8286648318228665}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.316196</td>\n",
       "      <td>{'mae': 2.1000733752049467}</td>\n",
       "      <td>{'mse': 3.065184807918818}</td>\n",
       "      <td>{'pearsonr': 0.8271512350104726}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.296980</td>\n",
       "      <td>{'mae': 2.1277309079006845}</td>\n",
       "      <td>{'mse': 3.0615044906207993}</td>\n",
       "      <td>{'pearsonr': 0.8277208798059337}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.233062</td>\n",
       "      <td>{'mae': 2.1340912458709047}</td>\n",
       "      <td>{'mse': 3.0508715109173603}</td>\n",
       "      <td>{'pearsonr': 0.8292311461895064}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.781400</td>\n",
       "      <td>9.339172</td>\n",
       "      <td>{'mae': 2.1165033201616126}</td>\n",
       "      <td>{'mse': 3.0688783926878074}</td>\n",
       "      <td>{'pearsonr': 0.8271042767440775}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.397967</td>\n",
       "      <td>{'mae': 2.132248461775973}</td>\n",
       "      <td>{'mse': 3.078507034214892}</td>\n",
       "      <td>{'pearsonr': 0.8285832153489865}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.424561</td>\n",
       "      <td>{'mae': 2.1314369736210947}</td>\n",
       "      <td>{'mse': 3.083052951824403}</td>\n",
       "      <td>{'pearsonr': 0.8264963890076661}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.310314</td>\n",
       "      <td>{'mae': 2.1256953509817573}</td>\n",
       "      <td>{'mse': 3.0643672117676375}</td>\n",
       "      <td>{'pearsonr': 0.8281773435213355}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.446681</td>\n",
       "      <td>{'mae': 2.1641492622379723}</td>\n",
       "      <td>{'mse': 3.0862797980581274}</td>\n",
       "      <td>{'pearsonr': 0.8275637429307205}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.506989</td>\n",
       "      <td>{'mae': 2.1413756881646697}</td>\n",
       "      <td>{'mse': 3.096462741379719}</td>\n",
       "      <td>{'pearsonr': 0.8264977734873055}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.328687</td>\n",
       "      <td>{'mae': 2.1207768441400097}</td>\n",
       "      <td>{'mse': 3.0673291650958308}</td>\n",
       "      <td>{'pearsonr': 0.8265052669982215}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.558634</td>\n",
       "      <td>{'mae': 2.1695860981052446}</td>\n",
       "      <td>{'mse': 3.1045359709441613}</td>\n",
       "      <td>{'pearsonr': 0.8259070829117026}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.535265</td>\n",
       "      <td>{'mae': 2.157993555882104}</td>\n",
       "      <td>{'mse': 3.100915083923436}</td>\n",
       "      <td>{'pearsonr': 0.826317708057065}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.484413</td>\n",
       "      <td>{'mae': 2.129206588936185}</td>\n",
       "      <td>{'mse': 3.093008994449604}</td>\n",
       "      <td>{'pearsonr': 0.8255510331616791}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>9.493134</td>\n",
       "      <td>{'mae': 2.1339518032816764}</td>\n",
       "      <td>{'mse': 3.0941100732968225}</td>\n",
       "      <td>{'pearsonr': 0.825198473091006}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.560088</td>\n",
       "      <td>{'mae': 2.1357654198852893}</td>\n",
       "      <td>{'mse': 3.1051726176636554}</td>\n",
       "      <td>{'pearsonr': 0.824421398036433}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.274356</td>\n",
       "      <td>{'mae': 2.0984771800638757}</td>\n",
       "      <td>{'mse': 3.058360726692836}</td>\n",
       "      <td>{'pearsonr': 0.8249288570598592}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.497753</td>\n",
       "      <td>{'mae': 2.1340740867299477}</td>\n",
       "      <td>{'mse': 3.094967325745493}</td>\n",
       "      <td>{'pearsonr': 0.824869264667217}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.554995</td>\n",
       "      <td>{'mae': 2.143620536771371}</td>\n",
       "      <td>{'mse': 3.104163125925734}</td>\n",
       "      <td>{'pearsonr': 0.8246730635641703}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.621126</td>\n",
       "      <td>{'mae': 2.1456625406171765}</td>\n",
       "      <td>{'mse': 3.114994955252294}</td>\n",
       "      <td>{'pearsonr': 0.8236933376367912}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.595473</td>\n",
       "      <td>{'mae': 2.163036822355565}</td>\n",
       "      <td>{'mse': 3.110694573554409}</td>\n",
       "      <td>{'pearsonr': 0.8240980944503902}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.629477</td>\n",
       "      <td>{'mae': 2.1539651840773937}</td>\n",
       "      <td>{'mse': 3.116305341750729}</td>\n",
       "      <td>{'pearsonr': 0.8238434368452208}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.482371</td>\n",
       "      <td>{'mae': 2.148270704079098}</td>\n",
       "      <td>{'mse': 3.092103329036446}</td>\n",
       "      <td>{'pearsonr': 0.8236552007539679}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.643720</td>\n",
       "      <td>{'mae': 2.1707858517766}</td>\n",
       "      <td>{'mse': 3.118315346826129}</td>\n",
       "      <td>{'pearsonr': 0.8248207005067656}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>9.518335</td>\n",
       "      <td>{'mae': 2.1516285063651615}</td>\n",
       "      <td>{'mse': 3.097926063052016}</td>\n",
       "      <td>{'pearsonr': 0.824951915158291}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.573492</td>\n",
       "      <td>{'mae': 2.152424830196397}</td>\n",
       "      <td>{'mse': 3.1070230662204867}</td>\n",
       "      <td>{'pearsonr': 0.8254280324396784}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.455622</td>\n",
       "      <td>{'mae': 2.135149923488876}</td>\n",
       "      <td>{'mse': 3.0877486296590466}</td>\n",
       "      <td>{'pearsonr': 0.8250811697111098}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.512001</td>\n",
       "      <td>{'mae': 2.144819556399802}</td>\n",
       "      <td>{'mse': 3.096955301080085}</td>\n",
       "      <td>{'pearsonr': 0.8253879727814988}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.583882</td>\n",
       "      <td>{'mae': 2.1518656165353236}</td>\n",
       "      <td>{'mse': 3.1087481852770633}</td>\n",
       "      <td>{'pearsonr': 0.8253298376314195}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.490746</td>\n",
       "      <td>{'mae': 2.143720069682689}</td>\n",
       "      <td>{'mse': 3.0935963217902502}</td>\n",
       "      <td>{'pearsonr': 0.82568313250946}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.461779</td>\n",
       "      <td>{'mae': 2.1326910255070266}</td>\n",
       "      <td>{'mse': 3.088929481957885}</td>\n",
       "      <td>{'pearsonr': 0.8257001021794157}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.425106</td>\n",
       "      <td>{'mae': 2.1272514552293997}</td>\n",
       "      <td>{'mse': 3.0829240118918646}</td>\n",
       "      <td>{'pearsonr': 0.8258792864263866}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.457388</td>\n",
       "      <td>{'mae': 2.131712105153554}</td>\n",
       "      <td>{'mse': 3.0882083718298805}</td>\n",
       "      <td>{'pearsonr': 0.8258699002264073}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.441409</td>\n",
       "      <td>{'mae': 2.1353635794771506}</td>\n",
       "      <td>{'mse': 3.0855080013999294}</td>\n",
       "      <td>{'pearsonr': 0.8260423626212963}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.522500</td>\n",
       "      <td>9.454111</td>\n",
       "      <td>{'mae': 2.135443575150773}</td>\n",
       "      <td>{'mse': 3.0875863885823223}</td>\n",
       "      <td>{'pearsonr': 0.8260721538895872}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.509300</td>\n",
       "      <td>9.459973</td>\n",
       "      <td>{'mae': 2.135878713801503}</td>\n",
       "      <td>{'mse': 3.088546781638058}</td>\n",
       "      <td>{'pearsonr': 0.8260698629832457}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-1500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-2500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-3500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-4500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-5500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-6500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1/checkpoint-7500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 16\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7500, training_loss=5.589815755208333, metrics={'train_runtime': 857.9802, 'train_samples_per_second': 137.94, 'train_steps_per_second': 8.741, 'total_flos': 1090452192307200.0, 'train_loss': 5.589815755208333, 'epoch': 150.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c152ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#take care of distributed/paralelle training \n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model \n",
    "model_to_save.save_pretrained(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4fb37c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.109,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.144,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 464,\n",
      "  \"is_gpu\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 515,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"norm_mean\": [\n",
      "    11.199569164274653,\n",
      "    -0.9728601944583675,\n",
      "    11.199595401578872,\n",
      "    0.1914454376660732,\n",
      "    0.608589373135307,\n",
      "    365.064017672,\n",
      "    342.24912812000014,\n",
      "    364.6033136038417,\n",
      "    134.06547,\n",
      "    0.004249,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    1.1861084842221647,\n",
      "    1.890967178564785,\n",
      "    2.519587985439997,\n",
      "    2.0112818114267816,\n",
      "    795.5621221754437,\n",
      "    18.14439203724506,\n",
      "    14.536240385432393,\n",
      "    15.215140271072487,\n",
      "    12.068994414289726,\n",
      "    8.453657900068215,\n",
      "    9.114162139055054,\n",
      "    6.434168605708085,\n",
      "    7.215103879809845,\n",
      "    4.436200487997215,\n",
      "    5.109730699855831,\n",
      "    3.055231525907226,\n",
      "    3.6252747118486264,\n",
      "    -2.202564923376624,\n",
      "    18.195385007867852,\n",
      "    7.9706993589944775,\n",
      "    4.5379164631837545,\n",
      "    150.95250337667272,\n",
      "    13.184208966483704,\n",
      "    8.814008658052902,\n",
      "    3.8191839078987306,\n",
      "    3.4969386790830774,\n",
      "    2.9222201316693712,\n",
      "    2.644444123964607,\n",
      "    6.408740449956927,\n",
      "    4.95314480536345,\n",
      "    2.6263770771853108,\n",
      "    2.4113616526384853,\n",
      "    26.24052195128434,\n",
      "    37.102909834641714,\n",
      "    19.89943953042712,\n",
      "    16.353848799228413,\n",
      "    15.638332143998122,\n",
      "    21.706094849865753,\n",
      "    0.28727529762970366,\n",
      "    8.054432014422119,\n",
      "    3.2648099385428853,\n",
      "    32.629006626588726,\n",
      "    16.26551059790217,\n",
      "    47.70605007162041,\n",
      "    0.0,\n",
      "    5.325837027308287,\n",
      "    9.698460925314944,\n",
      "    5.573601891254677,\n",
      "    2.581492771453006,\n",
      "    7.3124961943884665,\n",
      "    33.07539073817076,\n",
      "    10.718462271839512,\n",
      "    6.99277406210818,\n",
      "    31.684923475431933,\n",
      "    36.92162447084414,\n",
      "    1.2074202610211657,\n",
      "    5.110701506051421,\n",
      "    0.0,\n",
      "    71.04050338999998,\n",
      "    9.57750975344203,\n",
      "    10.066085526965992,\n",
      "    0.07691213090851719,\n",
      "    13.38923196114951,\n",
      "    16.862422387837878,\n",
      "    21.382953923695233,\n",
      "    15.651918121909311,\n",
      "    14.440634953378058,\n",
      "    19.13130604146014,\n",
      "    22.114944705243296,\n",
      "    8.183429061888226,\n",
      "    13.699768012021506,\n",
      "    2.1212691930096144,\n",
      "    17.474216494453906,\n",
      "    7.8467696174922725,\n",
      "    2.6683841482907034,\n",
      "    0.11868201225906093,\n",
      "    9.064881467380093,\n",
      "    2.659801877718109,\n",
      "    4.055917032498944,\n",
      "    0.259848432909807,\n",
      "    0.413963629624058,\n",
      "    25.186704,\n",
      "    1.79722,\n",
      "    5.353545,\n",
      "    0.272499,\n",
      "    0.562898,\n",
      "    0.835397,\n",
      "    1.236854,\n",
      "    0.729917,\n",
      "    1.966771,\n",
      "    4.216321,\n",
      "    1.414081,\n",
      "    6.486208,\n",
      "    5.688314,\n",
      "    0.205632,\n",
      "    0.409204,\n",
      "    0.614836,\n",
      "    2.802168,\n",
      "    2.7549044689500004,\n",
      "    97.31541557350002,\n",
      "    0.069051,\n",
      "    0.151924,\n",
      "    0.130758,\n",
      "    0.06279,\n",
      "    0.027038,\n",
      "    0.999062,\n",
      "    0.096951,\n",
      "    0.042862,\n",
      "    0.096089,\n",
      "    0.100163,\n",
      "    1.033857,\n",
      "    1.034286,\n",
      "    0.016206,\n",
      "    0.00357,\n",
      "    0.016776,\n",
      "    1.488795,\n",
      "    0.915699,\n",
      "    0.232236,\n",
      "    0.012241,\n",
      "    0.074885,\n",
      "    0.131561,\n",
      "    0.096951,\n",
      "    0.004026,\n",
      "    0.009835,\n",
      "    0.011646,\n",
      "    0.250196,\n",
      "    0.131237,\n",
      "    0.768633,\n",
      "    0.015927,\n",
      "    0.539599,\n",
      "    0.451885,\n",
      "    0.001726,\n",
      "    0.003335,\n",
      "    0.001218,\n",
      "    1.236474,\n",
      "    0.000226,\n",
      "    0.555529,\n",
      "    0.000149,\n",
      "    0.001046,\n",
      "    0.002578,\n",
      "    0.126995,\n",
      "    0.732216,\n",
      "    0.037978,\n",
      "    0.019179,\n",
      "    0.720141,\n",
      "    0.018951,\n",
      "    0.013025,\n",
      "    0.059523,\n",
      "    0.027553,\n",
      "    0.000831,\n",
      "    0.0002,\n",
      "    0.073914,\n",
      "    0.061694,\n",
      "    0.002249,\n",
      "    0.007716,\n",
      "    0.236426,\n",
      "    0.0287,\n",
      "    0.05231,\n",
      "    0.041425,\n",
      "    0.033421,\n",
      "    0.017275,\n",
      "    0.001082,\n",
      "    0.011915,\n",
      "    0.004249,\n",
      "    0.196769,\n",
      "    0.039316,\n",
      "    0.038686,\n",
      "    0.00409,\n",
      "    0.003615,\n",
      "    0.116124,\n",
      "    0.051192,\n",
      "    0.025177,\n",
      "    0.0,\n",
      "    0.161908,\n",
      "    0.315775,\n",
      "    0.087229,\n",
      "    0.079586,\n",
      "    0.023227,\n",
      "    0.005966,\n",
      "    0.007901,\n",
      "    0.050376,\n",
      "    0.000186,\n",
      "    0.065723,\n",
      "    0.380193,\n",
      "    0.051566\n",
      "  ],\n",
      "  \"norm_std\": [\n",
      "    2.9210526350021033,\n",
      "    1.5294133532822065,\n",
      "    2.9209947673330334,\n",
      "    0.21956154740898992,\n",
      "    0.22097666681598954,\n",
      "    160.48566423804579,\n",
      "    151.38170855657367,\n",
      "    160.3304390667665,\n",
      "    60.484857692625106,\n",
      "    0.181038611279414,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.24851193112366385,\n",
      "    0.317494124851492,\n",
      "    0.37175815103599535,\n",
      "    0.6098706561111424,\n",
      "    539.8195290502504,\n",
      "    8.140940922894863,\n",
      "    6.600767667198695,\n",
      "    6.700942921964325,\n",
      "    5.536318526756788,\n",
      "    4.020569431789569,\n",
      "    4.316039675035455,\n",
      "    3.229701298304296,\n",
      "    4.058753110098356,\n",
      "    2.399274478688092,\n",
      "    4.590084765547685,\n",
      "    1.8657465201411236,\n",
      "    8.197075845395899,\n",
      "    1.3989800795766576,\n",
      "    8.727770321711972,\n",
      "    4.719034225006412,\n",
      "    3.6844834579923407,\n",
      "    66.65125255607474,\n",
      "    11.022808176926917,\n",
      "    9.88512023443511,\n",
      "    5.895101555004671,\n",
      "    6.0315631910071374,\n",
      "    4.465786134186721,\n",
      "    8.73293454096314,\n",
      "    7.292192943139112,\n",
      "    5.798809757257198,\n",
      "    5.458840154330179,\n",
      "    5.34562222799046,\n",
      "    28.624753237838462,\n",
      "    22.7685485030176,\n",
      "    13.735506972569182,\n",
      "    12.75558914023291,\n",
      "    12.647297666063738,\n",
      "    16.73803715869515,\n",
      "    1.3236865505015507,\n",
      "    8.012917117258175,\n",
      "    6.328266302270954,\n",
      "    30.80439768300023,\n",
      "    14.510669158473307,\n",
      "    33.76748799216324,\n",
      "    0.0,\n",
      "    8.851153866015428,\n",
      "    8.222102882220607,\n",
      "    7.329351085680612,\n",
      "    4.87773057457412,\n",
      "    10.796349487508557,\n",
      "    24.55359833254403,\n",
      "    10.33295824604808,\n",
      "    8.986884190324291,\n",
      "    26.77991276665104,\n",
      "    29.521288543995215,\n",
      "    4.077418430037268,\n",
      "    11.23487898363004,\n",
      "    0.0,\n",
      "    50.277243284807206,\n",
      "    19.12173183245714,\n",
      "    9.819697177666312,\n",
      "    1.4201437981599128,\n",
      "    12.511435257208836,\n",
      "    14.212538029397628,\n",
      "    16.973978925056553,\n",
      "    19.21649041911615,\n",
      "    15.092240504961104,\n",
      "    19.889237093009676,\n",
      "    25.80872442073538,\n",
      "    9.254317550453825,\n",
      "    19.013243564373347,\n",
      "    3.6841568734614953,\n",
      "    17.690679185577395,\n",
      "    10.27595457263499,\n",
      "    3.3283202642652645,\n",
      "    2.8773795244438474,\n",
      "    9.228734822190495,\n",
      "    5.106296483962912,\n",
      "    4.008127533955226,\n",
      "    2.3345092198667503,\n",
      "    0.23958883840178574,\n",
      "    11.48532061063049,\n",
      "    2.0042680181777808,\n",
      "    3.411142707197923,\n",
      "    0.7103265443180337,\n",
      "    0.8009597262862117,\n",
      "    1.0630493791282618,\n",
      "    1.2495037990913607,\n",
      "    0.8592211073826755,\n",
      "    1.4909738617970663,\n",
      "    2.8049912821495706,\n",
      "    1.5692082041123125,\n",
      "    3.7188860712382157,\n",
      "    4.918753910447648,\n",
      "    0.6213838320183964,\n",
      "    0.6971589290933399,\n",
      "    0.9385507839118636,\n",
      "    1.7370945619837506,\n",
      "    2.7759468746763334,\n",
      "    43.91556441471313,\n",
      "    0.2929625321198007,\n",
      "    0.6742399816263887,\n",
      "    0.6447563579731193,\n",
      "    0.26136083143708466,\n",
      "    0.1703202147866646,\n",
      "    1.3696411924562566,\n",
      "    0.3394696140137124,\n",
      "    0.26977939457438505,\n",
      "    0.3350074869447194,\n",
      "    0.3408584597974497,\n",
      "    1.2690580420372088,\n",
      "    1.2684116362885036,\n",
      "    0.1297126917051003,\n",
      "    0.06304965563156611,\n",
      "    0.17914965229828922,\n",
      "    1.485673805113914,\n",
      "    1.1656052934139842,\n",
      "    0.5018632205797633,\n",
      "    0.15576643470973517,\n",
      "    0.2883562378800223,\n",
      "    0.3774901929558512,\n",
      "    0.3394696140137124,\n",
      "    0.07983606764988928,\n",
      "    0.10307416455777559,\n",
      "    0.11692041889415362,\n",
      "    1.0010868912132271,\n",
      "    0.7705779932112281,\n",
      "    1.157481598590082,\n",
      "    0.13507534533122212,\n",
      "    0.8359812306885952,\n",
      "    0.7600865243553028,\n",
      "    0.04757124327808961,\n",
      "    0.07183232513905516,\n",
      "    0.03513570421263404,\n",
      "    1.239225396368063,\n",
      "    0.015097985029438593,\n",
      "    1.3364349277900949,\n",
      "    0.013378265133341392,\n",
      "    0.032663541616103894,\n",
      "    0.060970137226002974,\n",
      "    0.44400840883756576,\n",
      "    1.159532265122051,\n",
      "    0.198246590935912,\n",
      "    0.1491817288215558,\n",
      "    1.28126795861232,\n",
      "    0.143114919141507,\n",
      "    0.11579880303510387,\n",
      "    0.25012811724209466,\n",
      "    0.1830406121462275,\n",
      "    0.03504726333553974,\n",
      "    0.015295758691880374,\n",
      "    0.3034514997274073,\n",
      "    0.2749689545601939,\n",
      "    0.04859983910409953,\n",
      "    0.09878498419533764,\n",
      "    0.5707110234042025,\n",
      "    0.17028898672063034,\n",
      "    0.24456026600763192,\n",
      "    0.21322057789532142,\n",
      "    0.1917343827305721,\n",
      "    0.13591391704896466,\n",
      "    0.03519702423260403,\n",
      "    0.11080182783711219,\n",
      "    0.0680510883818226,\n",
      "    0.5264724473438641,\n",
      "    0.2602735481879015,\n",
      "    0.25847912916802446,\n",
      "    0.10886360159063149,\n",
      "    0.10026934640727359,\n",
      "    0.35113436163289397,\n",
      "    0.2260341350934195,\n",
      "    0.16874580630684471,\n",
      "    0.0,\n",
      "    0.4146998571400424,\n",
      "    0.5347143492505464,\n",
      "    0.3137422508894841,\n",
      "    0.27962501103110715,\n",
      "    0.1547563582555832,\n",
      "    0.08130444916739461,\n",
      "    0.08949068223889126,\n",
      "    0.22530492534853602,\n",
      "    0.014421012861987593,\n",
      "    0.2736413019822887,\n",
      "    2.253629375384596,\n",
      "    0.22817317920167496\n",
      "  ],\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 600\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at C:/Users/pj11/Documents/bert_finetune2/hansen_h_fold1//model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making prediction \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_output_path)\n",
    "\n",
    "# arguments for Trainer\n",
    "test_args = TrainingArguments(\n",
    "     output_dir =model_output_path,\n",
    "     do_train = False,\n",
    "     do_predict = True,\n",
    "     dataloader_drop_last = False\n",
    ")\n",
    "\n",
    "# Init Trainer\n",
    "trainer=Trainer(\n",
    "          model = model,\n",
    "          args = test_args,\n",
    "          compute_metrics = compute_metrics)\n",
    "\n",
    "test_results = trainer.predict(small_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27ef5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.9,  1. ,  3.2,  0. ,  5.5,  8.5, 17.6,  4.3,  4. ,  8. ,  1.4,\n",
       "        9.2,  6.2,  4.1,  6.2,  7.5,  5.2, 10.7, 10. ,  8.4,  4. ,  8.2,\n",
       "       16. ,  4.9, 21. , 11.8, 10.6,  5.4,  3.8,  3.6,  3.1,  5.7,  9.6,\n",
       "        0. ,  4.6,  4.8, 12. ,  7.3,  7.5, 13. ,  6. ,  5.2,  5.9, 10.8,\n",
       "        8.2, 10.3, 14.6, 11.3, 14.5, 11. ,  5.6, 13. ,  7. ,  6.4,  7.6,\n",
       "        3.8,  0. ,  2.9,  0. ,  5.9, 10.2,  4.1,  3.7,  2.4,  4.1, 14.2,\n",
       "        0. ,  7.8,  8.6, 13. , 20.2,  5. , 12. , 11.7,  0. ,  6.5,  5.7,\n",
       "       19.5, 14. , 12.9,  5.9,  1.8,  6.2,  5.8, 10.9,  5.7,  4.5,  9. ,\n",
       "        7.5,  6.7,  4. , 13.4, 13.3, 17.7, 10.5,  5.7,  7.5, 13.8, 14.6,\n",
       "       19. , 14. ,  6.7,  3.9,  7. ,  5.1,  2. ,  4.1,  5.6, 14.3,  8.8,\n",
       "       14.9, 12.3,  2.2,  1. ,  5.9, 10.8,  3.1,  4.5,  5.3,  2. ,  9. ,\n",
       "       18.8,  2.3,  8. ,  5.7,  0. ,  5.9,  6.6,  0. ,  3.8,  5.3,  2. ,\n",
       "        1.1,  1.7,  0.6,  7.8,  7. , 21.1, 11.9, 10.7, 12.8,  0. ,  1.8,\n",
       "        8. ,  0.2,  7.5,  4.1,  5.6,  8.4,  5.3, 11.5,  8.6,  3.7,  2.6,\n",
       "        7.8,  3.5,  7.2, 20.3,  3.1, 12.3,  1. ,  5.6,  2.7,  5.9, 17. ,\n",
       "        2.9, 16.3,  5.5, 27.2,  4.1,  5.4,  1.2,  4.9, 15.8,  5.1,  9. ,\n",
       "       13.8,  0.6,  2.2,  7.6,  5.9,  3. ,  8.4,  2. ,  3.8,  0. ,  0. ,\n",
       "        7.4,  9.1,  7.5, 16.8,  7.7,  5.1,  6.3,  4.8,  3.2,  7.6],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out prediction in test set\n",
    "test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09656a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 5.846280574798584,\n",
       " 'test_mae': {'mae': 1.7118928342736162},\n",
       " 'test_rmse': {'mse': 2.4175193191947684},\n",
       " 'test_pearsonr': {'pearsonr': 0.8990642611467261},\n",
       " 'test_runtime': 0.9829,\n",
       " 'test_samples_per_second': 200.434,\n",
       " 'test_steps_per_second': 7.122}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out metric in test set\n",
    "test_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362ec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7118928\n",
      "2.4175192764918076\n",
      "0.8039249866770309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "# MAE, AE and RMSE give an idea of the error distribution\n",
    "print(mean_absolute_error(test_results[0], test_results[1]))\n",
    "\n",
    "#RMSEs\n",
    "print(math.sqrt(mean_squared_error(test_results[0], test_results[1])))\n",
    "\n",
    "# R^2 Coefficient of Determination\n",
    "print(r2_score(test_results[0], test_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef967db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred. Hansen h')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot exp vs pred in test set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "ln = np.arange(0, 30, 0.2)\n",
    "plt.plot(ln, ln,'r--')\n",
    "plt.scatter(test_results[1], test_results[0])\n",
    "plt.xlabel('exp. Hansen h')\n",
    "plt.ylabel('pred. Hansen h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred_test=pd.DataFrame(test_results[0], columns=[\"predict\"])\n",
    "pd_exp_test=pd.DataFrame(test_results[1], columns=[\"exp\"])\n",
    "pd_smiles=pd.DataFrame(dataset['test']['smiles'], columns=[\"smiles\"])\n",
    "pd_test=pd.concat((pd_smiles, pd_exp_test, pd_pred_test), axis=1)\n",
    "\n",
    "# save predicton to csv \n",
    "pd_test.to_csv('hansen_h_bert_ds6_fold1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5108c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04564f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f50f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
