{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0df1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c986d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b6509ab990ce4a0e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/pj11/.cache/huggingface/datasets/csv/default-b6509ab990ce4a0e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bc0723a8da40a9b2f3f19ad9a8a9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0075768031488f88dc693291bfdd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/pj11/.cache/huggingface/datasets/csv/default-b6509ab990ce4a0e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a384e9eed434423bd5fd4ddc03a3f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data into training, valdidation and test\n",
    "dataset = load_dataset('csv', data_files={'train':['hansen_d_bert_ds1.csv', 'hansen_d_bert_ds2.csv',\n",
    "                                                   'hansen_d_bert_ds3.csv', 'hansen_d_bert_ds4.csv'],\n",
    "                                          'validation':'hansen_d_bert_ds5.csv',\n",
    "                                          'test': 'hansen_d_bert_ds6.csv'}, delimiter=',', column_names =['smiles', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9874b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': 'CC\\\\C(C)=N\\\\O', 'label': 14.7}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data format\n",
    "dataset['validation'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9894c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# specify model from hugging face\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b48772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7933beee99d04510bdc34f5f0614a86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3727838abcfc409b9a73665be62a7b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e506116327646429acf5592ab6afec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009f538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 789\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f040040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=random_state).select(range(1000))\n",
    "#small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=random_state).select(range(1000))\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]\n",
    "small_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b5f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# for regression, num_labels=1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663b29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90cab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metric\n",
    "mae_metric = evaluate.load(\"mae\")\n",
    "mse_metric = evaluate.load(\"mse\")\n",
    "pearsonr_metric = evaluate.load(\"pearsonr\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update({'mae': mae_metric.compute(predictions=predictions, references=labels)})\n",
    "    metrics.update({'rmse': mse_metric.compute(predictions=predictions, references=labels, squared=False)})\n",
    "    metrics.update({'pearsonr': pearsonr_metric.compute(predictions=predictions, references=labels)})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574f2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the finetuned model\n",
    "para_output_dir = 'C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/'\n",
    "model_output_path = f'{para_output_dir}/model'\n",
    "\n",
    "# specify trainining arguments \n",
    "training_args = TrainingArguments(output_dir=para_output_dir, \n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  #per_device_train_batch_size = 64,\n",
    "                                  #per_device_eval_batch_size = 64,\n",
    "                                  num_train_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794a8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 789\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1250\n",
      "  Number of trainable parameters = 44104705\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 08:32, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Pearsonr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>55.576160</td>\n",
       "      <td>{'mae': 7.223409047586664}</td>\n",
       "      <td>{'mse': 7.457740726145153}</td>\n",
       "      <td>{'pearsonr': 0.08701955853098609}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>24.270010</td>\n",
       "      <td>{'mae': 4.5748671081465515}</td>\n",
       "      <td>{'mse': 4.929453583184772}</td>\n",
       "      <td>{'pearsonr': 0.030872241552578568}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.977970</td>\n",
       "      <td>{'mae': 3.1434673173778553}</td>\n",
       "      <td>{'mse': 3.605711150536933}</td>\n",
       "      <td>{'pearsonr': 0.045574993397273875}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.197320</td>\n",
       "      <td>{'mae': 2.0996739392353194}</td>\n",
       "      <td>{'mse': 2.6861878953582616}</td>\n",
       "      <td>{'pearsonr': 0.06685095911032571}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.283473</td>\n",
       "      <td>{'mae': 1.5658483263199705}</td>\n",
       "      <td>{'mse': 2.073023447589096}</td>\n",
       "      <td>{'pearsonr': 0.08346354734677303}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.473547</td>\n",
       "      <td>{'mae': 1.524745127876398}</td>\n",
       "      <td>{'mse': 1.8666746191498131}</td>\n",
       "      <td>{'pearsonr': 0.5793395834195899}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.485485</td>\n",
       "      <td>{'mae': 1.1856397057547787}</td>\n",
       "      <td>{'mse': 1.5802231829741324}</td>\n",
       "      <td>{'pearsonr': 0.7988154780857367}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.522821</td>\n",
       "      <td>{'mae': 0.9297629612956555}</td>\n",
       "      <td>{'mse': 1.2347726087317894}</td>\n",
       "      <td>{'pearsonr': 0.8421307833882609}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.244070</td>\n",
       "      <td>{'mae': 0.8367156643552829}</td>\n",
       "      <td>{'mse': 1.1180303992346787}</td>\n",
       "      <td>{'pearsonr': 0.870603324210816}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.004166</td>\n",
       "      <td>{'mae': 0.7324277180705578}</td>\n",
       "      <td>{'mse': 1.0036657655530243}</td>\n",
       "      <td>{'pearsonr': 0.8734972657213289}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.783997</td>\n",
       "      <td>{'mae': 0.6517760765734057}</td>\n",
       "      <td>{'mse': 0.8853055433154884}</td>\n",
       "      <td>{'pearsonr': 0.8979651881776289}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.871188</td>\n",
       "      <td>{'mae': 0.6958830199265843}</td>\n",
       "      <td>{'mse': 0.9353166145061033}</td>\n",
       "      <td>{'pearsonr': 0.867384141746309}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.993394</td>\n",
       "      <td>{'mae': 0.787431213456362}</td>\n",
       "      <td>{'mse': 0.9966669133372064}</td>\n",
       "      <td>{'pearsonr': 0.8884753684061472}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733573</td>\n",
       "      <td>{'mae': 0.6439176549766269}</td>\n",
       "      <td>{'mse': 0.8551140200054661}</td>\n",
       "      <td>{'pearsonr': 0.8887535548987402}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.113517</td>\n",
       "      <td>{'mae': 0.8525396821462563}</td>\n",
       "      <td>{'mse': 1.0533217916983466}</td>\n",
       "      <td>{'pearsonr': 0.8982879116953075}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.735585</td>\n",
       "      <td>{'mae': 0.6339471545921365}</td>\n",
       "      <td>{'mse': 0.8582979173274581}</td>\n",
       "      <td>{'pearsonr': 0.891415655948063}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.763615</td>\n",
       "      <td>{'mae': 0.663766962622628}</td>\n",
       "      <td>{'mse': 0.8739488704084403}</td>\n",
       "      <td>{'pearsonr': 0.8927737674250449}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.848441</td>\n",
       "      <td>{'mae': 0.700203029032286}</td>\n",
       "      <td>{'mse': 0.9198466162870975}</td>\n",
       "      <td>{'pearsonr': 0.8889288160972906}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.779989</td>\n",
       "      <td>{'mae': 0.6616960322191268}</td>\n",
       "      <td>{'mse': 0.8816356206788407}</td>\n",
       "      <td>{'pearsonr': 0.8969816899063245}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.760790</td>\n",
       "      <td>{'mae': 0.6526082227677863}</td>\n",
       "      <td>{'mse': 0.8713483846666834}</td>\n",
       "      <td>{'pearsonr': 0.8899675008732075}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.840465</td>\n",
       "      <td>{'mae': 0.7189265895010856}</td>\n",
       "      <td>{'mse': 0.914284554554064}</td>\n",
       "      <td>{'pearsonr': 0.8968764240354983}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.760240</td>\n",
       "      <td>{'mae': 0.6632968108666125}</td>\n",
       "      <td>{'mse': 0.8708921016619291}</td>\n",
       "      <td>{'pearsonr': 0.8981827044796149}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.722689</td>\n",
       "      <td>{'mae': 0.6403563058920924}</td>\n",
       "      <td>{'mse': 0.8489159630416085}</td>\n",
       "      <td>{'pearsonr': 0.8909036551079053}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.752802</td>\n",
       "      <td>{'mae': 0.6566247455964839}</td>\n",
       "      <td>{'mse': 0.866619001006888}</td>\n",
       "      <td>{'pearsonr': 0.89090855058804}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.769198</td>\n",
       "      <td>{'mae': 0.6599531657804693}</td>\n",
       "      <td>{'mse': 0.8745856470359703}</td>\n",
       "      <td>{'pearsonr': 0.8929957259300128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>{'mae': 0.6909321770450185}</td>\n",
       "      <td>{'mse': 0.904487919677207}</td>\n",
       "      <td>{'pearsonr': 0.8903418301047912}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>{'mae': 0.7764157958442185}</td>\n",
       "      <td>{'mse': 0.9711958677641348}</td>\n",
       "      <td>{'pearsonr': 0.8947811205360963}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.755257</td>\n",
       "      <td>{'mae': 0.6550711762481535}</td>\n",
       "      <td>{'mse': 0.8675276022623407}</td>\n",
       "      <td>{'pearsonr': 0.8961142859643694}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.707415</td>\n",
       "      <td>{'mae': 0.6318275480706075}</td>\n",
       "      <td>{'mse': 0.839328924386328}</td>\n",
       "      <td>{'pearsonr': 0.8964916174098512}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.719758</td>\n",
       "      <td>{'mae': 0.6229234927801917}</td>\n",
       "      <td>{'mse': 0.8464371008726816}</td>\n",
       "      <td>{'pearsonr': 0.894798295511325}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.733633</td>\n",
       "      <td>{'mae': 0.6321826489443706}</td>\n",
       "      <td>{'mse': 0.8546789760854963}</td>\n",
       "      <td>{'pearsonr': 0.8927558124950197}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.726614</td>\n",
       "      <td>{'mae': 0.6351854740665649}</td>\n",
       "      <td>{'mse': 0.8496644337207985}</td>\n",
       "      <td>{'pearsonr': 0.8954102531740776}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.770461</td>\n",
       "      <td>{'mae': 0.6436895476985098}</td>\n",
       "      <td>{'mse': 0.8752404425626278}</td>\n",
       "      <td>{'pearsonr': 0.8948813384435078}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.728662</td>\n",
       "      <td>{'mae': 0.6266254241091346}</td>\n",
       "      <td>{'mse': 0.8515810329160732}</td>\n",
       "      <td>{'pearsonr': 0.8942611465787016}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.677035</td>\n",
       "      <td>{'mae': 0.5953855272477049}</td>\n",
       "      <td>{'mse': 0.8211030758120292}</td>\n",
       "      <td>{'pearsonr': 0.8987174784736472}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.699946</td>\n",
       "      <td>{'mae': 0.6190069314792072}</td>\n",
       "      <td>{'mse': 0.8353693279134454}</td>\n",
       "      <td>{'pearsonr': 0.8956384706606887}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>{'mae': 0.647714856917483}</td>\n",
       "      <td>{'mse': 0.8666223051376837}</td>\n",
       "      <td>{'pearsonr': 0.8932826568455833}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.743546</td>\n",
       "      <td>{'mae': 0.630795290022332}</td>\n",
       "      <td>{'mse': 0.8606863177169035}</td>\n",
       "      <td>{'pearsonr': 0.891655119678128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>10.722100</td>\n",
       "      <td>0.734431</td>\n",
       "      <td>{'mae': 0.6286230861838094}</td>\n",
       "      <td>{'mse': 0.8551846202256966}</td>\n",
       "      <td>{'pearsonr': 0.8916931571217982}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.726573</td>\n",
       "      <td>{'mae': 0.6251154623660945}</td>\n",
       "      <td>{'mse': 0.8504030233799214}</td>\n",
       "      <td>{'pearsonr': 0.8947856811171405}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.706784</td>\n",
       "      <td>{'mae': 0.6144942511156731}</td>\n",
       "      <td>{'mse': 0.8392162806465157}</td>\n",
       "      <td>{'pearsonr': 0.8945406862534571}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.756158</td>\n",
       "      <td>{'mae': 0.6423633691623126}</td>\n",
       "      <td>{'mse': 0.8672911168935665}</td>\n",
       "      <td>{'pearsonr': 0.8957555026013202}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.720613</td>\n",
       "      <td>{'mae': 0.6200826567441678}</td>\n",
       "      <td>{'mse': 0.8467689222186736}</td>\n",
       "      <td>{'pearsonr': 0.893896584623913}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.760609</td>\n",
       "      <td>{'mae': 0.6408371659099753}</td>\n",
       "      <td>{'mse': 0.8701090285195807}</td>\n",
       "      <td>{'pearsonr': 0.8916174895226483}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.714520</td>\n",
       "      <td>{'mae': 0.6147125166684843}</td>\n",
       "      <td>{'mse': 0.8436367428755666}</td>\n",
       "      <td>{'pearsonr': 0.8947218945521039}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.738018</td>\n",
       "      <td>{'mae': 0.6307367721789985}</td>\n",
       "      <td>{'mse': 0.8573193699639424}</td>\n",
       "      <td>{'pearsonr': 0.8927677411576517}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.723357</td>\n",
       "      <td>{'mae': 0.6213756745236779}</td>\n",
       "      <td>{'mse': 0.8488261414507092}</td>\n",
       "      <td>{'pearsonr': 0.8926405961211908}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.740558</td>\n",
       "      <td>{'mae': 0.6306872682523001}</td>\n",
       "      <td>{'mse': 0.8586678426837547}</td>\n",
       "      <td>{'pearsonr': 0.8920330707109776}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.731772</td>\n",
       "      <td>{'mae': 0.6235919652251423}</td>\n",
       "      <td>{'mse': 0.8537026295590568}</td>\n",
       "      <td>{'pearsonr': 0.8923966053043396}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.729696</td>\n",
       "      <td>{'mae': 0.6230479835858805}</td>\n",
       "      <td>{'mse': 0.8525022263250225}</td>\n",
       "      <td>{'pearsonr': 0.8925102282768334}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-1000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1/checkpoint-1000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=4.41025719909668, metrics={'train_runtime': 519.9286, 'train_samples_per_second': 75.876, 'train_steps_per_second': 2.404, 'total_flos': 5225745681561600.0, 'train_loss': 4.41025719909668, 'epoch': 50.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c152ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#take care of distributed/paralelle training \n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model \n",
    "model_to_save.save_pretrained(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4fb37c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n",
      "loading weights file C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at C:/Users/pj11/Documents/bert_finetune/hansen_d_cross_val_fold1//model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making prediction \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_output_path)\n",
    "\n",
    "# arguments for Trainer\n",
    "test_args = TrainingArguments(\n",
    "     output_dir =model_output_path,\n",
    "     do_train = False,\n",
    "     do_predict = True,\n",
    "     dataloader_drop_last = False\n",
    ")\n",
    "\n",
    "# Init Trainer\n",
    "trainer=Trainer(\n",
    "          model = model,\n",
    "          args = test_args,\n",
    "          compute_metrics = compute_metrics)\n",
    "\n",
    "test_results = trainer.predict(small_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27ef5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.8, 16. , 15.6, 15.7, 17.8, 15.9, 17.2, 17.2, 18.8, 16. , 17.8,\n",
       "       16.5, 15. , 20. , 20. , 15.2, 15.4, 19.9, 20.2, 14. , 16. , 21. ,\n",
       "       14.4, 16.8, 17. , 19.4, 15.9, 15.8, 19.6, 19.5, 17.8, 18.7, 19. ,\n",
       "       19.2, 16.3, 20.3, 16.5, 17.1, 15.8, 18.3, 15.4, 15.4, 20.9, 15.3,\n",
       "       15.7, 15. , 17.5, 14.7, 15.8, 16. , 19.9, 19. , 15.5, 19.8, 18.5,\n",
       "       20.3, 16.5, 15.7, 15.7, 15.4, 15.8, 16.8, 16.2, 19. , 16.8, 16.4,\n",
       "       14.5, 18.7, 18.7, 19. , 16.3, 15.1, 16.8, 20.2, 14.9, 18.2, 20.5,\n",
       "       18.2, 14.6, 19.1, 15. , 16.4, 15.5, 20.4, 20.1, 15. , 16. , 15.9,\n",
       "       16.7, 20. , 15.5, 19.2, 15.6, 19.5, 17.3, 16.3, 16.4, 20.2, 17.5,\n",
       "       17.2, 16.1, 19.8, 18.7, 20. , 19. , 19.4, 15.3, 16.5, 19.5, 16.2,\n",
       "       20. , 16.9, 15.6, 17.4, 19. , 20. , 20. , 15.8, 19.5, 15.6, 17.5,\n",
       "       13.7, 19. , 19.2, 17.8, 16. , 16.3, 14.8, 16. , 15.3, 16.1, 17.8,\n",
       "       17.4, 21.3, 20.2, 18.9, 18.9, 20.7, 14.4, 20. , 17.6, 12.2, 14.6,\n",
       "       15.2, 16.8, 16.4, 16. , 18.2, 16. , 18.1, 17.4, 15. , 19.9, 19.1,\n",
       "       18.3, 14.9, 16.5, 18.6, 18. , 19.7, 12.8, 15.7, 19.7, 15.8, 16.6,\n",
       "       14.6, 17.1, 17.5, 17.4, 18.6, 15.9, 18.1, 20. , 16. , 17.8, 12.3,\n",
       "       18.3, 17.8, 18.9, 15.3, 15.7, 15.2, 21. , 17.4, 19.5, 17.4, 15.3,\n",
       "       17.9, 16.5, 17.6, 16.2, 15.5, 16.4, 15.8, 15.2, 18.8, 15. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out prediction in test set\n",
    "test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09656a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.7187657952308655,\n",
       " 'test_mae': {'mae': 0.6068708303616132},\n",
       " 'test_rmse': {'mse': 0.8470046836767883},\n",
       " 'test_pearsonr': {'pearsonr': 0.9007303605635548},\n",
       " 'test_runtime': 1.7333,\n",
       " 'test_samples_per_second': 113.656,\n",
       " 'test_steps_per_second': 4.039}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out metric in test set\n",
    "test_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362ec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60687083\n",
      "0.847004723554859\n",
      "0.716069752207027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "# MAE, AE and RMSE give an idea of the error distribution\n",
    "print(mean_absolute_error(test_results[0], test_results[1]))\n",
    "\n",
    "#RMSEs\n",
    "print(math.sqrt(mean_squared_error(test_results[0], test_results[1])))\n",
    "\n",
    "# R^2 Coefficient of Determination\n",
    "print(r2_score(test_results[0], test_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef967db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred. Hansen d')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot exp vs pred in test set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "ln = np.arange(10, 25, 0.2)\n",
    "plt.plot(ln, ln,'r--')\n",
    "plt.scatter(test_results[1], test_results[0])\n",
    "plt.xlabel('exp. Hansen d')\n",
    "plt.ylabel('pred. Hansen d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred_test=pd.DataFrame(test_results[0], columns=[\"predict\"])\n",
    "pd_exp_test=pd.DataFrame(test_results[1], columns=[\"exp\"])\n",
    "pd_smiles=pd.DataFrame(dataset['test']['smiles'], columns=[\"smiles\"])\n",
    "pd_test=pd.concat((pd_smiles, pd_exp_test, pd_pred_test), axis=1)\n",
    "\n",
    "# save predicton to csv \n",
    "pd_test.to_csv('hansen_d_bert_ds6_fold1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5108c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>exp</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC#N</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.580278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1CCCC1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.744991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCC(CC)CNCC(CC)CCCC</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>16.126049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCCCCCCCC</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>15.747732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(CCCCCCCCC(=O)OCc1ccccc1)OCc2ccccc2</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>18.508404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CC=CCC#N</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>16.336565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CCCCOC(C)=O</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>16.131983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CC(C)=C=O</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>15.892619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Fc1cccc(F)c1C#N</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>18.636156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CCC(C)OC(C)=O</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.744164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     smiles        exp    predict\n",
       "0                                      SC#N  16.799999  16.580278\n",
       "1                                  CC1CCCC1  16.000000  16.744991\n",
       "2                     CCCCC(CC)CNCC(CC)CCCC  15.600000  16.126049\n",
       "3                                CCCCCCCCCC  15.700000  15.747732\n",
       "4    O=C(CCCCCCCCC(=O)OCc1ccccc1)OCc2ccccc2  17.799999  18.508404\n",
       "..                                      ...        ...        ...\n",
       "192                                CC=CCC#N  16.400000  16.336565\n",
       "193                             CCCCOC(C)=O  15.800000  16.131983\n",
       "194                               CC(C)=C=O  15.200000  15.892619\n",
       "195                         Fc1cccc(F)c1C#N  18.799999  18.636156\n",
       "196                           CCC(C)OC(C)=O  15.000000  15.744164\n",
       "\n",
       "[197 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04564f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
