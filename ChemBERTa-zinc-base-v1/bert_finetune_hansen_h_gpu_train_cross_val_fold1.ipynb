{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0df1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c986d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7d3a2f2466763cf8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/pj11/.cache/huggingface/datasets/csv/default-7d3a2f2466763cf8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbee6f140a2942fba71544f554a0ccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47151ccc02fb4c57b6463a3cee349064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/pj11/.cache/huggingface/datasets/csv/default-7d3a2f2466763cf8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21545fe9cc8d47fc818ad6b6ea068aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train':['hansen_h_bert_ds1.csv', 'hansen_h_bert_ds2.csv',\n",
    "                                                   'hansen_h_bert_ds3.csv', 'hansen_h_bert_ds4.csv'],\n",
    "                                          'validation':'hansen_h_bert_ds5.csv',\n",
    "                                          'test': 'hansen_h_bert_ds6.csv'}, delimiter=',', column_names =['smiles', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9874b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': 'CC\\\\C(C)=N\\\\O', 'label': 7.8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9894c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b48772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccf7b6a75c840378546935de2ac102a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7487f7777e48b9879a9ccd52b51ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb9f77d7fa4475997175a6706bf3ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009f538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 789\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f040040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=random_state).select(range(1000))\n",
    "#small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=random_state).select(range(1000))\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]\n",
    "small_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b5f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# for regression, num_labels=1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663b29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90cab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_metric = evaluate.load(\"mae\")\n",
    "mse_metric = evaluate.load(\"mse\")\n",
    "pearsonr_metric = evaluate.load(\"pearsonr\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update({'mae': mae_metric.compute(predictions=predictions, references=labels)})\n",
    "    metrics.update({'rmse': mse_metric.compute(predictions=predictions, references=labels, squared=False)})\n",
    "    metrics.update({'pearsonr': pearsonr_metric.compute(predictions=predictions, references=labels)})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574f2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_output_dir = 'C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/'\n",
    "model_output_path = f'{para_output_dir}/model'\n",
    "\n",
    "training_args = TrainingArguments(output_dir=para_output_dir, \n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  #per_device_train_batch_size = 64,\n",
    "                                  #per_device_eval_batch_size = 64,\n",
    "                                  num_train_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794a8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 789\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1250\n",
      "  Number of trainable parameters = 44104705\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 08:22, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Pearsonr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>25.510918</td>\n",
       "      <td>{'mae': 3.9472666210329472}</td>\n",
       "      <td>{'mse': 5.037851100457441}</td>\n",
       "      <td>{'pearsonr': 0.3321296859907823}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>20.166626</td>\n",
       "      <td>{'mae': 3.2526835590449688}</td>\n",
       "      <td>{'mse': 4.481804800571155}</td>\n",
       "      <td>{'pearsonr': 0.5542735621971777}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>18.153715</td>\n",
       "      <td>{'mae': 3.192760278730828}</td>\n",
       "      <td>{'mse': 4.257327237509609}</td>\n",
       "      <td>{'pearsonr': 0.6060300998309368}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>14.016592</td>\n",
       "      <td>{'mae': 2.579914667279587}</td>\n",
       "      <td>{'mse': 3.741534234073636}</td>\n",
       "      <td>{'pearsonr': 0.7297891627543767}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.140087</td>\n",
       "      <td>{'mae': 2.4162114671795503}</td>\n",
       "      <td>{'mse': 3.621642983912274}</td>\n",
       "      <td>{'pearsonr': 0.7423826961641686}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.939969</td>\n",
       "      <td>{'mae': 2.2998145181818055}</td>\n",
       "      <td>{'mse': 3.4531679681969853}</td>\n",
       "      <td>{'pearsonr': 0.7540977177922952}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.057774</td>\n",
       "      <td>{'mae': 2.247762613981811}</td>\n",
       "      <td>{'mse': 3.3275572853969093}</td>\n",
       "      <td>{'pearsonr': 0.7721579370105507}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.780910</td>\n",
       "      <td>{'mae': 2.539199041533591}</td>\n",
       "      <td>{'mse': 3.575890661621068}</td>\n",
       "      <td>{'pearsonr': 0.7383389569448413}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.703259</td>\n",
       "      <td>{'mae': 2.3320353249664687}</td>\n",
       "      <td>{'mse': 3.422922233562919}</td>\n",
       "      <td>{'pearsonr': 0.7607411751353427}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.312476</td>\n",
       "      <td>{'mae': 2.2933387317633267}</td>\n",
       "      <td>{'mse': 3.5173226192922695}</td>\n",
       "      <td>{'pearsonr': 0.7472528247537669}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.585885</td>\n",
       "      <td>{'mae': 2.3857636671078386}</td>\n",
       "      <td>{'mse': 3.4111172599677437}</td>\n",
       "      <td>{'pearsonr': 0.7637045585475395}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>10.217296</td>\n",
       "      <td>{'mae': 2.198853500300858}</td>\n",
       "      <td>{'mse': 3.2055741242201554}</td>\n",
       "      <td>{'pearsonr': 0.79452595614829}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.511244</td>\n",
       "      <td>{'mae': 2.408249829928887}</td>\n",
       "      <td>{'mse': 3.5430786700741734}</td>\n",
       "      <td>{'pearsonr': 0.7378453431650778}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.037582</td>\n",
       "      <td>{'mae': 2.1240185959841393}</td>\n",
       "      <td>{'mse': 3.329604577464148}</td>\n",
       "      <td>{'pearsonr': 0.7739895431324818}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.070181</td>\n",
       "      <td>{'mae': 2.295631396362019}</td>\n",
       "      <td>{'mse': 3.3316470037790866}</td>\n",
       "      <td>{'pearsonr': 0.7747330163056553}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.128041</td>\n",
       "      <td>{'mae': 2.268030512718682}</td>\n",
       "      <td>{'mse': 3.348200425666483}</td>\n",
       "      <td>{'pearsonr': 0.7692081694448495}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.693636</td>\n",
       "      <td>{'mae': 2.499567762168531}</td>\n",
       "      <td>{'mse': 3.428054065406823}</td>\n",
       "      <td>{'pearsonr': 0.776376336010994}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.448758</td>\n",
       "      <td>{'mae': 2.2324891987488353}</td>\n",
       "      <td>{'mse': 3.3927173049834365}</td>\n",
       "      <td>{'pearsonr': 0.7604734065251748}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.891065</td>\n",
       "      <td>{'mae': 2.3638673576001588}</td>\n",
       "      <td>{'mse': 3.454692975727482}</td>\n",
       "      <td>{'pearsonr': 0.7571764808518138}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.659812</td>\n",
       "      <td>{'mae': 2.450823515993992}</td>\n",
       "      <td>{'mse': 3.42409075177226}</td>\n",
       "      <td>{'pearsonr': 0.7728192800843339}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.044144</td>\n",
       "      <td>{'mae': 2.273423616656192}</td>\n",
       "      <td>{'mse': 3.3308401376488566}</td>\n",
       "      <td>{'pearsonr': 0.7741922981126317}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.626813</td>\n",
       "      <td>{'mae': 2.2250495034123436}</td>\n",
       "      <td>{'mse': 3.4169177520835774}</td>\n",
       "      <td>{'pearsonr': 0.7584692789088059}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.887854</td>\n",
       "      <td>{'mae': 2.197002704373471}</td>\n",
       "      <td>{'mse': 3.4576234492067557}</td>\n",
       "      <td>{'pearsonr': 0.7496854487421409}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.392006</td>\n",
       "      <td>{'mae': 2.1911390127831605}</td>\n",
       "      <td>{'mse': 3.383130314974673}</td>\n",
       "      <td>{'pearsonr': 0.7622345763300343}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>10.845421</td>\n",
       "      <td>{'mae': 2.2298672722255444}</td>\n",
       "      <td>{'mse': 3.2997126862434762}</td>\n",
       "      <td>{'pearsonr': 0.7791154604560544}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>10.951255</td>\n",
       "      <td>{'mae': 2.2586902031287326}</td>\n",
       "      <td>{'mse': 3.315714771481406}</td>\n",
       "      <td>{'pearsonr': 0.7788504784909231}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.347084</td>\n",
       "      <td>{'mae': 2.1869679187013187}</td>\n",
       "      <td>{'mse': 3.375470019194779}</td>\n",
       "      <td>{'pearsonr': 0.7656463860603282}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.326524</td>\n",
       "      <td>{'mae': 2.134840153895205}</td>\n",
       "      <td>{'mse': 3.373714458388469}</td>\n",
       "      <td>{'pearsonr': 0.7678738462942405}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.340393</td>\n",
       "      <td>{'mae': 2.158871603571824}</td>\n",
       "      <td>{'mse': 3.3740022501058546}</td>\n",
       "      <td>{'pearsonr': 0.7637408317731604}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>10.854667</td>\n",
       "      <td>{'mae': 2.175255397173959}</td>\n",
       "      <td>{'mse': 3.3004464992948144}</td>\n",
       "      <td>{'pearsonr': 0.7762339533026079}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.106535</td>\n",
       "      <td>{'mae': 2.111451707213058}</td>\n",
       "      <td>{'mse': 3.344638660092426}</td>\n",
       "      <td>{'pearsonr': 0.7695095496469251}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.059981</td>\n",
       "      <td>{'mae': 2.2386603990787175}</td>\n",
       "      <td>{'mse': 3.3321614754324944}</td>\n",
       "      <td>{'pearsonr': 0.7729904957624938}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>10.994823</td>\n",
       "      <td>{'mae': 2.1754866280228957}</td>\n",
       "      <td>{'mse': 3.324182321907711}</td>\n",
       "      <td>{'pearsonr': 0.772413676209601}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>10.845351</td>\n",
       "      <td>{'mae': 2.1855747288253706}</td>\n",
       "      <td>{'mse': 3.301950853391688}</td>\n",
       "      <td>{'pearsonr': 0.7760003951197622}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.217532</td>\n",
       "      <td>{'mae': 2.1635212736383913}</td>\n",
       "      <td>{'mse': 3.355740943605958}</td>\n",
       "      <td>{'pearsonr': 0.766821962172197}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.160532</td>\n",
       "      <td>{'mae': 2.1666871266921763}</td>\n",
       "      <td>{'mse': 3.3482164620909702}</td>\n",
       "      <td>{'pearsonr': 0.7679364569899614}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.212176</td>\n",
       "      <td>{'mae': 2.206748550313378}</td>\n",
       "      <td>{'mse': 3.354058986360566}</td>\n",
       "      <td>{'pearsonr': 0.7672604575266426}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.400133</td>\n",
       "      <td>{'mae': 2.2944076642167146}</td>\n",
       "      <td>{'mse': 3.3809687890407445}</td>\n",
       "      <td>{'pearsonr': 0.7675452375531668}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>9.900300</td>\n",
       "      <td>11.280878</td>\n",
       "      <td>{'mae': 2.2155223980092154}</td>\n",
       "      <td>{'mse': 3.366198865845712}</td>\n",
       "      <td>{'pearsonr': 0.7658516914349283}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.330699</td>\n",
       "      <td>{'mae': 2.1265034410856702}</td>\n",
       "      <td>{'mse': 3.3748472542128303}</td>\n",
       "      <td>{'pearsonr': 0.7672632068892772}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.120661</td>\n",
       "      <td>{'mae': 2.160001191164031}</td>\n",
       "      <td>{'mse': 3.343031768739331}</td>\n",
       "      <td>{'pearsonr': 0.7683885178442115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.167502</td>\n",
       "      <td>{'mae': 2.1704289324695085}</td>\n",
       "      <td>{'mse': 3.3487872054458014}</td>\n",
       "      <td>{'pearsonr': 0.7677468038943454}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.346649</td>\n",
       "      <td>{'mae': 2.180736972104172}</td>\n",
       "      <td>{'mse': 3.375911884239507}</td>\n",
       "      <td>{'pearsonr': 0.763418274914866}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.240602</td>\n",
       "      <td>{'mae': 2.172309079146022}</td>\n",
       "      <td>{'mse': 3.3614272220634467}</td>\n",
       "      <td>{'pearsonr': 0.7655342431522577}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.167879</td>\n",
       "      <td>{'mae': 2.143007740264919}</td>\n",
       "      <td>{'mse': 3.3508991998316824}</td>\n",
       "      <td>{'pearsonr': 0.7672681632270341}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.045315</td>\n",
       "      <td>{'mae': 2.1672122410030537}</td>\n",
       "      <td>{'mse': 3.332377205279402}</td>\n",
       "      <td>{'pearsonr': 0.7709180553330057}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.211247</td>\n",
       "      <td>{'mae': 2.184144683598262}</td>\n",
       "      <td>{'mse': 3.357449434237805}</td>\n",
       "      <td>{'pearsonr': 0.7664267721170629}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.190943</td>\n",
       "      <td>{'mae': 2.180891834681636}</td>\n",
       "      <td>{'mse': 3.3533015588369204}</td>\n",
       "      <td>{'pearsonr': 0.767703056442495}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.191898</td>\n",
       "      <td>{'mae': 2.1646824077074296}</td>\n",
       "      <td>{'mse': 3.3542077714314584}</td>\n",
       "      <td>{'pearsonr': 0.7666570052432871}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.944700</td>\n",
       "      <td>11.237015</td>\n",
       "      <td>{'mae': 2.1552117993856594}</td>\n",
       "      <td>{'mse': 3.36117011746393}</td>\n",
       "      <td>{'pearsonr': 0.765518189122532}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-500\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Saving model checkpoint to C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-1000\n",
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1/checkpoint-1000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=5.578670458984375, metrics={'train_runtime': 511.5607, 'train_samples_per_second': 77.117, 'train_steps_per_second': 2.444, 'total_flos': 5225745681561600.0, 'train_loss': 5.578670458984375, 'epoch': 50.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c152ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model\\config.json\n",
      "Model weights saved in C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#take care of distributed/paralelle training \n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model \n",
    "model_to_save.save_pretrained(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4fb37c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n",
      "loading weights file C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at C:/Users/pj11/Documents/bert_finetune/hansen_h_cross_val_fold1//model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: smiles. If smiles are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 197\n",
      "  Batch size = 32\n",
      "C:\\Users\\pj11\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making prediction \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_output_path)\n",
    "\n",
    "# arguments for Trainer\n",
    "test_args = TrainingArguments(\n",
    "     output_dir =model_output_path,\n",
    "     do_train = False,\n",
    "     do_predict = True,\n",
    "     dataloader_drop_last = False\n",
    ")\n",
    "\n",
    "# Init Trainer\n",
    "trainer=Trainer(\n",
    "          model = model,\n",
    "          args = test_args,\n",
    "          compute_metrics = compute_metrics)\n",
    "\n",
    "test_results = trainer.predict(small_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27ef5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.9,  1. ,  3.2,  0. ,  5.5,  8.5, 17.6,  4.3,  4. ,  8. ,  1.4,\n",
       "        9.2,  6.2,  4.1,  6.2,  7.5,  5.2, 10.7, 10. ,  8.4,  4. ,  8.2,\n",
       "       16. ,  4.9, 21. , 11.8, 10.6,  5.4,  3.8,  3.6,  3.1,  5.7,  9.6,\n",
       "        0. ,  4.6,  4.8, 12. ,  7.3,  7.5, 13. ,  6. ,  5.2,  5.9, 10.8,\n",
       "        8.2, 10.3, 14.6, 11.3, 14.5, 11. ,  5.6, 13. ,  7. ,  6.4,  7.6,\n",
       "        3.8,  0. ,  2.9,  0. ,  5.9, 10.2,  4.1,  3.7,  2.4,  4.1, 14.2,\n",
       "        0. ,  7.8,  8.6, 13. , 20.2,  5. , 12. , 11.7,  0. ,  6.5,  5.7,\n",
       "       19.5, 14. , 12.9,  5.9,  1.8,  6.2,  5.8, 10.9,  5.7,  4.5,  9. ,\n",
       "        7.5,  6.7,  4. , 13.4, 13.3, 17.7, 10.5,  5.7,  7.5, 13.8, 14.6,\n",
       "       19. , 14. ,  6.7,  3.9,  7. ,  5.1,  2. ,  4.1,  5.6, 14.3,  8.8,\n",
       "       14.9, 12.3,  2.2,  1. ,  5.9, 10.8,  3.1,  4.5,  5.3,  2. ,  9. ,\n",
       "       18.8,  2.3,  8. ,  5.7,  0. ,  5.9,  6.6,  0. ,  3.8,  5.3,  2. ,\n",
       "        1.1,  1.7,  0.6,  7.8,  7. , 21.1, 11.9, 10.7, 12.8,  0. ,  1.8,\n",
       "        8. ,  0.2,  7.5,  4.1,  5.6,  8.4,  5.3, 11.5,  8.6,  3.7,  2.6,\n",
       "        7.8,  3.5,  7.2, 20.3,  3.1, 12.3,  1. ,  5.6,  2.7,  5.9, 17. ,\n",
       "        2.9, 16.3,  5.5, 27.2,  4.1,  5.4,  1.2,  4.9, 15.8,  5.1,  9. ,\n",
       "       13.8,  0.6,  2.2,  7.6,  5.9,  3. ,  8.4,  2. ,  3.8,  0. ,  0. ,\n",
       "        7.4,  9.1,  7.5, 16.8,  7.7,  5.1,  6.3,  4.8,  3.2,  7.6],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09656a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 8.151893615722656,\n",
       " 'test_mae': {'mae': 1.7779674674880686},\n",
       " 'test_rmse': {'mse': 2.8557219026969594},\n",
       " 'test_pearsonr': {'pearsonr': 0.827209818848175},\n",
       " 'test_runtime': 1.6493,\n",
       " 'test_samples_per_second': 119.447,\n",
       " 'test_steps_per_second': 4.244}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362ec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7779675\n",
      "2.855721729933769\n",
      "0.5864926067278177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "# MAE, AE and RMSE give an idea of the error distribution\n",
    "print(mean_absolute_error(test_results[0], test_results[1]))\n",
    "\n",
    "#RMSEs\n",
    "print(math.sqrt(mean_squared_error(test_results[0], test_results[1])))\n",
    "\n",
    "# R^2 Coefficient of Determination\n",
    "print(r2_score(test_results[0], test_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef967db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred. Hansen h')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "ln = np.arange(0, 30, 0.2)\n",
    "plt.plot(ln, ln,'r--')\n",
    "plt.scatter(test_results[1], test_results[0])\n",
    "plt.xlabel('exp. Hansen h')\n",
    "plt.ylabel('pred. Hansen h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred_test=pd.DataFrame(test_results[0], columns=[\"predict\"])\n",
    "pd_exp_test=pd.DataFrame(test_results[1], columns=[\"exp\"])\n",
    "pd_smiles=pd.DataFrame(dataset['test']['smiles'], columns=[\"smiles\"])\n",
    "pd_test=pd.concat((pd_smiles, pd_exp_test, pd_pred_test), axis=1)\n",
    "\n",
    "# save predicton to csv \n",
    "pd_test.to_csv('hansen_h_bert_ds6_fold1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5108c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>exp</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC#N</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6.721265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1CCCC1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.252125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCC(CC)CNCC(CC)CCCC</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.982227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCCCCCCCC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(CCCCCCCCC(=O)OCc1ccccc1)OCc2ccccc2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.696132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CC=CCC#N</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.690761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CCCCOC(C)=O</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.363953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CC(C)=C=O</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.658949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Fc1cccc(F)c1C#N</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.822671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CCC(C)OC(C)=O</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.763206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     smiles   exp   predict\n",
       "0                                      SC#N  10.9  6.721265\n",
       "1                                  CC1CCCC1   1.0  2.252125\n",
       "2                     CCCCC(CC)CNCC(CC)CCCC   3.2  3.982227\n",
       "3                                CCCCCCCCCC   0.0  0.439862\n",
       "4    O=C(CCCCCCCCC(=O)OCc1ccccc1)OCc2ccccc2   5.5  5.696132\n",
       "..                                      ...   ...       ...\n",
       "192                                CC=CCC#N   5.1  5.690761\n",
       "193                             CCCCOC(C)=O   6.3  6.363953\n",
       "194                               CC(C)=C=O   4.8  6.658949\n",
       "195                         Fc1cccc(F)c1C#N   3.2  2.822671\n",
       "196                           CCC(C)OC(C)=O   7.6  7.763206\n",
       "\n",
       "[197 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04564f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
